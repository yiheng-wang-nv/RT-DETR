W1227 14:27:49.195000 155 torch/distributed/run.py:793] 
W1227 14:27:49.195000 155 torch/distributed/run.py:793] *****************************************
W1227 14:27:49.195000 155 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1227 14:27:49.195000 155 torch/distributed/run.py:793] *****************************************
Initialized distributed mode...
cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': '/colon_workspace/RT-DETR/rtdetrv2_pytorch/output/rtdetrv2_r50vd_6x_coco/best.pth', 'epoches': 72, 'last_epoch': -1, 'use_amp': False, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 1, 'output_dir': './output/rtdetrv2_r50vd_6x_coco', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 1, 'remap_mscoco_category': True, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/colon_workspace/real-colon-dataset/real_colon_dataset_coco_fmt_3subsets_poslesion1000_negratio0/train_images', 'ann_file': '/colon_workspace/real-colon-dataset/real_colon_dataset_coco_fmt_3subsets_poslesion1000_negratio0/train_ann.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 16, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 64}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/colon_workspace/real-colon-dataset/real_colon_dataset_coco_fmt_3subsets_poslesion1000_negratio0/test_images', 'ann_file': '/colon_workspace/real-colon-dataset/real_colon_dataset_coco_fmt_3subsets_poslesion1000_negratio0/test_ann.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 16, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 128}, 'print_freq': 100, 'output_dir': './output/rtdetrv2_r50vd_6x_coco', 'checkpoint_freq': 1, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': False, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'epoches': 72, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*norm).*$', 'lr': 4e-06}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 4e-05, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': True}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/dataset/colon_detection.yml', '/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/runtime.yml', '/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/include/dataloader.yml', '/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/include/optimizer.yml', '/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/include/rtdetrv2_r50vd.yml'], 'config': '/colon_workspace/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r50vd_6x_coco.yml', 'tuning': '/colon_workspace/RT-DETR/rtdetrv2_pytorch/output/rtdetrv2_r50vd_6x_coco/best.pth', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}
Start training
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
  0%|          | 0.00/90.0M [00:00<?, ?B/s] 12%|█▏        | 10.6M/90.0M [00:00<00:00, 111MB/s] 32%|███▏      | 28.6M/90.0M [00:00<00:00, 156MB/s]Initialized distributed mode...Initialized distributed mode...

 48%|████▊     | 43.6M/90.0M [00:00<00:00, 108MB/s] 63%|██████▎   | 56.8M/90.0M [00:00<00:00, 117MB/s]Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
 78%|███████▊  | 70.1M/90.0M [00:00<00:00, 94.4MB/s]Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Initialized distributed mode...
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
 96%|█████████▋| 86.9M/90.0M [00:00<00:00, 115MB/s] Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
Downloading: "https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth" to /home/holoscan/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth
100%|██████████| 90.0M/90.0M [00:00<00:00, 108MB/s]
Load PResNet50 state_dict
  0%|          | 0.00/90.0M [00:00<?, ?B/s]  0%|          | 0.00/90.0M [00:00<?, ?B/s]  0%|          | 0.00/90.0M [00:00<?, ?B/s]tuning checkpoint from /colon_workspace/RT-DETR/rtdetrv2_pytorch/output/rtdetrv2_r50vd_6x_coco/best.pth
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
  0%|          | 0.00/90.0M [00:00<?, ?B/s]/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
 11%|█         | 10.1M/90.0M [00:00<00:00, 105MB/s] 11%|█         | 10.1M/90.0M [00:00<00:00, 104MB/s]/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
 43%|████▎     | 38.9M/90.0M [00:00<00:00, 407MB/s]  0%|          | 0.00/90.0M [00:00<?, ?B/s]/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
 28%|██▊       | 25.5M/90.0M [00:00<00:00, 267MB/s]  0%|          | 0.00/90.0M [00:00<?, ?B/s] 23%|██▎       | 21.1M/90.0M [00:00<00:00, 111MB/s] 24%|██▍       | 21.6M/90.0M [00:00<00:00, 114MB/s]  0%|          | 0.00/90.0M [00:00<?, ?B/s] 13%|█▎        | 11.8M/90.0M [00:00<00:00, 122MB/s] 86%|████████▋ | 77.8M/90.0M [00:00<00:00, 364MB/s] 60%|██████    | 54.2M/90.0M [00:00<00:00, 287MB/s]100%|██████████| 90.0M/90.0M [00:00<00:00, 369MB/s]
  2%|▏         | 1.38M/90.0M [00:00<00:06, 14.1MB/s] 35%|███▌      | 31.8M/90.0M [00:00<00:00, 111MB/s] 36%|███▌      | 32.5M/90.0M [00:00<00:00, 112MB/s]  1%|          | 512k/90.0M [00:00<00:18, 5.11MB/s] 41%|████▏     | 37.2M/90.0M [00:00<00:00, 207MB/s]100%|██████████| 90.0M/90.0M [00:00<00:00, 323MB/s]
  9%|▊         | 7.75M/90.0M [00:00<00:01, 44.7MB/s] 47%|████▋     | 42.4M/90.0M [00:00<00:00, 111MB/s] 48%|████▊     | 43.2M/90.0M [00:00<00:00, 112MB/s]  8%|▊         | 7.00M/90.0M [00:00<00:02, 41.7MB/s] 38%|███▊      | 34.5M/90.0M [00:00<00:00, 151MB/s]  36%|███▌      | 32.1M/90.0M [00:00<00:00, 142MB/s]  59%|█████▉    | 53.0M/90.0M [00:00<00:00, 107MB/s] 60%|█████▉    | 54.0M/90.0M [00:00<00:00, 108MB/s] 63%|██████▎   | 57.1M/90.0M [00:00<00:00, 149MB/s] 67%|██████▋   | 60.1M/90.0M [00:00<00:00, 191MB/s] 67%|██████▋   | 60.5M/90.0M [00:00<00:00, 201MB/s] 70%|███████   | 63.2M/90.0M [00:00<00:00, 103MB/s] 71%|███████▏  | 64.4M/90.0M [00:00<00:00, 103MB/s]Load model.state_dict, {'missed': [], 'unmatched': []}
 81%|████████  | 72.9M/90.0M [00:00<00:00, 112MB/s] 81%|████████  | 73.1M/90.0M [00:00<00:00, 95.6MB/s] 83%|████████▎ | 74.4M/90.0M [00:00<00:00, 96.2MB/s] 87%|████████▋ | 78.2M/90.0M [00:00<00:00, 153MB/s] 89%|████████▊ | 79.8M/90.0M [00:00<00:00, 160MB/s]/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
 91%|█████████▏| 82.4M/90.0M [00:00<00:00, 94.7MB/s] 93%|█████████▎| 83.8M/90.0M [00:00<00:00, 95.4MB/s] 95%|█████████▍| 85.2M/90.0M [00:00<00:00, 111MB/s]/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
100%|██████████| 90.0M/90.0M [00:00<00:00, 128MB/s]
100%|██████████| 90.0M/90.0M [00:00<00:00, 130MB/s]
100%|██████████| 90.0M/90.0M [00:00<00:00, 101MB/s] 
100%|██████████| 90.0M/90.0M [00:00<00:00, 101MB/s] 
100%|██████████| 90.0M/90.0M [00:00<00:00, 118MB/s]
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
/colon_workspace/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(path, map_location='cpu')
Initial lr: [4e-06, 4e-05, 4e-05]
building train_dataloader with batch_size=4...
loading annotations into memory...
Done (t=1.18s)
creating index...
index created!
building val_dataloader with batch_size=8...
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
number of trainable parameters: 42700515
Epoch: [0]  [   0/1519]  eta: 5:53:43  lr: 0.000004  lr2: 0.000040  loss: 12.3388 (12.3388)  loss_bbox: 0.1802 (0.1802)  loss_bbox_aux_0: 0.1705 (0.1705)  loss_bbox_aux_1: 0.1808 (0.1808)  loss_bbox_aux_2: 0.1842 (0.1842)  loss_bbox_aux_3: 0.1803 (0.1803)  loss_bbox_aux_4: 0.1802 (0.1802)  loss_bbox_dn_0: 0.2462 (0.2462)  loss_bbox_dn_1: 0.2003 (0.2003)  loss_bbox_dn_2: 0.1933 (0.1933)  loss_bbox_dn_3: 0.1921 (0.1921)  loss_bbox_dn_4: 0.1912 (0.1912)  loss_bbox_dn_5: 0.1912 (0.1912)  loss_bbox_enc_0: 0.2069 (0.2069)  loss_giou: 0.3276 (0.3276)  loss_giou_aux_0: 0.3442 (0.3442)  loss_giou_aux_1: 0.3310 (0.3310)  loss_giou_aux_2: 0.3295 (0.3295)  loss_giou_aux_3: 0.3258 (0.3258)  loss_giou_aux_4: 0.3276 (0.3276)  loss_giou_dn_0: 0.3745 (0.3745)  loss_giou_dn_1: 0.3119 (0.3119)  loss_giou_dn_2: 0.3031 (0.3031)  loss_giou_dn_3: 0.3017 (0.3017)  loss_giou_dn_4: 0.3015 (0.3015)  loss_giou_dn_5: 0.3015 (0.3015)  loss_giou_enc_0: 0.3742 (0.3742)  loss_vfl: 0.4924 (0.4924)  loss_vfl_aux_0: 0.5464 (0.5464)  loss_vfl_aux_1: 0.5220 (0.5220)  loss_vfl_aux_2: 0.5024 (0.5024)  loss_vfl_aux_3: 0.4937 (0.4937)  loss_vfl_aux_4: 0.4865 (0.4865)  loss_vfl_dn_0: 0.3634 (0.3634)  loss_vfl_dn_1: 0.3270 (0.3270)  loss_vfl_dn_2: 0.3221 (0.3221)  loss_vfl_dn_3: 0.3215 (0.3215)  loss_vfl_dn_4: 0.3208 (0.3208)  loss_vfl_dn_5: 0.3209 (0.3209)  loss_vfl_enc_0: 0.5679 (0.5679)  time: 13.9723  data: 5.0721  max mem: 2581
Epoch: [0]  [ 100/1519]  eta: 0:15:10  lr: 0.000004  lr2: 0.000040  loss: 10.5511 (10.9843)  loss_bbox: 0.1281 (0.1355)  loss_bbox_aux_0: 0.1352 (0.1407)  loss_bbox_aux_1: 0.1283 (0.1350)  loss_bbox_aux_2: 0.1291 (0.1346)  loss_bbox_aux_3: 0.1284 (0.1348)  loss_bbox_aux_4: 0.1281 (0.1352)  loss_bbox_dn_0: 0.1506 (0.1670)  loss_bbox_dn_1: 0.1277 (0.1371)  loss_bbox_dn_2: 0.1218 (0.1329)  loss_bbox_dn_3: 0.1206 (0.1315)  loss_bbox_dn_4: 0.1206 (0.1310)  loss_bbox_dn_5: 0.1206 (0.1310)  loss_bbox_enc_0: 0.1492 (0.1614)  loss_giou: 0.3054 (0.3251)  loss_giou_aux_0: 0.3193 (0.3358)  loss_giou_aux_1: 0.3073 (0.3264)  loss_giou_aux_2: 0.3063 (0.3248)  loss_giou_aux_3: 0.3060 (0.3250)  loss_giou_aux_4: 0.3054 (0.3245)  loss_giou_dn_0: 0.3339 (0.3549)  loss_giou_dn_1: 0.2800 (0.2965)  loss_giou_dn_2: 0.2724 (0.2894)  loss_giou_dn_3: 0.2706 (0.2881)  loss_giou_dn_4: 0.2703 (0.2879)  loss_giou_dn_5: 0.2702 (0.2879)  loss_giou_enc_0: 0.3649 (0.3827)  loss_vfl: 0.3696 (0.3921)  loss_vfl_aux_0: 0.4713 (0.5029)  loss_vfl_aux_1: 0.4183 (0.4408)  loss_vfl_aux_2: 0.3837 (0.4090)  loss_vfl_aux_3: 0.3727 (0.3961)  loss_vfl_aux_4: 0.3736 (0.3941)  loss_vfl_dn_0: 0.3604 (0.3651)  loss_vfl_dn_1: 0.3213 (0.3277)  loss_vfl_dn_2: 0.3164 (0.3228)  loss_vfl_dn_3: 0.3159 (0.3217)  loss_vfl_dn_4: 0.3156 (0.3214)  loss_vfl_dn_5: 0.3158 (0.3214)  loss_vfl_enc_0: 0.4966 (0.5126)  time: 0.5021  data: 0.0106  max mem: 5637
Epoch: [0]  [ 200/1519]  eta: 0:12:31  lr: 0.000004  lr2: 0.000040  loss: 10.9264 (10.9170)  loss_bbox: 0.1377 (0.1355)  loss_bbox_aux_0: 0.1382 (0.1408)  loss_bbox_aux_1: 0.1314 (0.1359)  loss_bbox_aux_2: 0.1356 (0.1353)  loss_bbox_aux_3: 0.1366 (0.1350)  loss_bbox_aux_4: 0.1377 (0.1353)  loss_bbox_dn_0: 0.1614 (0.1658)  loss_bbox_dn_1: 0.1341 (0.1356)  loss_bbox_dn_2: 0.1295 (0.1315)  loss_bbox_dn_3: 0.1301 (0.1300)  loss_bbox_dn_4: 0.1301 (0.1294)  loss_bbox_dn_5: 0.1302 (0.1295)  loss_bbox_enc_0: 0.1603 (0.1610)  loss_giou: 0.3146 (0.3243)  loss_giou_aux_0: 0.3389 (0.3351)  loss_giou_aux_1: 0.3212 (0.3261)  loss_giou_aux_2: 0.3138 (0.3245)  loss_giou_aux_3: 0.3153 (0.3241)  loss_giou_aux_4: 0.3251 (0.3239)  loss_giou_dn_0: 0.3552 (0.3528)  loss_giou_dn_1: 0.2952 (0.2942)  loss_giou_dn_2: 0.2872 (0.2872)  loss_giou_dn_3: 0.2867 (0.2859)  loss_giou_dn_4: 0.2863 (0.2856)  loss_giou_dn_5: 0.2862 (0.2857)  loss_giou_enc_0: 0.3782 (0.3802)  loss_vfl: 0.3871 (0.3895)  loss_vfl_aux_0: 0.4811 (0.4946)  loss_vfl_aux_1: 0.4342 (0.4351)  loss_vfl_aux_2: 0.3927 (0.4045)  loss_vfl_aux_3: 0.3912 (0.3932)  loss_vfl_aux_4: 0.3852 (0.3909)  loss_vfl_dn_0: 0.3652 (0.3637)  loss_vfl_dn_1: 0.3270 (0.3262)  loss_vfl_dn_2: 0.3232 (0.3214)  loss_vfl_dn_3: 0.3230 (0.3204)  loss_vfl_dn_4: 0.3225 (0.3201)  loss_vfl_dn_5: 0.3225 (0.3201)  loss_vfl_enc_0: 0.4895 (0.5072)  time: 0.4964  data: 0.0108  max mem: 5637
Epoch: [0]  [ 300/1519]  eta: 0:11:04  lr: 0.000004  lr2: 0.000040  loss: 10.9848 (10.8838)  loss_bbox: 0.1268 (0.1348)  loss_bbox_aux_0: 0.1349 (0.1404)  loss_bbox_aux_1: 0.1312 (0.1356)  loss_bbox_aux_2: 0.1295 (0.1349)  loss_bbox_aux_3: 0.1280 (0.1347)  loss_bbox_aux_4: 0.1279 (0.1347)  loss_bbox_dn_0: 0.1520 (0.1648)  loss_bbox_dn_1: 0.1264 (0.1346)  loss_bbox_dn_2: 0.1227 (0.1304)  loss_bbox_dn_3: 0.1226 (0.1289)  loss_bbox_dn_4: 0.1218 (0.1284)  loss_bbox_dn_5: 0.1218 (0.1284)  loss_bbox_enc_0: 0.1482 (0.1598)  loss_giou: 0.3167 (0.3235)  loss_giou_aux_0: 0.3296 (0.3345)  loss_giou_aux_1: 0.3240 (0.3258)  loss_giou_aux_2: 0.3171 (0.3239)  loss_giou_aux_3: 0.3158 (0.3235)  loss_giou_aux_4: 0.3189 (0.3233)  loss_giou_dn_0: 0.3444 (0.3525)  loss_giou_dn_1: 0.2855 (0.2939)  loss_giou_dn_2: 0.2817 (0.2867)  loss_giou_dn_3: 0.2807 (0.2855)  loss_giou_dn_4: 0.2804 (0.2852)  loss_giou_dn_5: 0.2802 (0.2853)  loss_giou_enc_0: 0.3743 (0.3791)  loss_vfl: 0.3856 (0.3882)  loss_vfl_aux_0: 0.4763 (0.4912)  loss_vfl_aux_1: 0.4231 (0.4320)  loss_vfl_aux_2: 0.4057 (0.4028)  loss_vfl_aux_3: 0.3835 (0.3917)  loss_vfl_aux_4: 0.3881 (0.3894)  loss_vfl_dn_0: 0.3629 (0.3633)  loss_vfl_dn_1: 0.3259 (0.3258)  loss_vfl_dn_2: 0.3216 (0.3210)  loss_vfl_dn_3: 0.3214 (0.3200)  loss_vfl_dn_4: 0.3208 (0.3196)  loss_vfl_dn_5: 0.3210 (0.3196)  loss_vfl_enc_0: 0.5041 (0.5060)  time: 0.4987  data: 0.0104  max mem: 5637
Epoch: [0]  [ 400/1519]  eta: 0:09:58  lr: 0.000004  lr2: 0.000040  loss: 10.7080 (10.8359)  loss_bbox: 0.1261 (0.1337)  loss_bbox_aux_0: 0.1331 (0.1392)  loss_bbox_aux_1: 0.1242 (0.1342)  loss_bbox_aux_2: 0.1214 (0.1338)  loss_bbox_aux_3: 0.1254 (0.1336)  loss_bbox_aux_4: 0.1261 (0.1337)  loss_bbox_dn_0: 0.1645 (0.1638)  loss_bbox_dn_1: 0.1350 (0.1339)  loss_bbox_dn_2: 0.1285 (0.1297)  loss_bbox_dn_3: 0.1285 (0.1282)  loss_bbox_dn_4: 0.1273 (0.1276)  loss_bbox_dn_5: 0.1273 (0.1276)  loss_bbox_enc_0: 0.1554 (0.1584)  loss_giou: 0.3178 (0.3212)  loss_giou_aux_0: 0.3330 (0.3325)  loss_giou_aux_1: 0.3213 (0.3235)  loss_giou_aux_2: 0.3174 (0.3217)  loss_giou_aux_3: 0.3139 (0.3212)  loss_giou_aux_4: 0.3178 (0.3211)  loss_giou_dn_0: 0.3561 (0.3507)  loss_giou_dn_1: 0.2891 (0.2923)  loss_giou_dn_2: 0.2835 (0.2851)  loss_giou_dn_3: 0.2804 (0.2839)  loss_giou_dn_4: 0.2793 (0.2835)  loss_giou_dn_5: 0.2793 (0.2836)  loss_giou_enc_0: 0.3829 (0.3773)  loss_vfl: 0.3808 (0.3878)  loss_vfl_aux_0: 0.4967 (0.4886)  loss_vfl_aux_1: 0.4457 (0.4312)  loss_vfl_aux_2: 0.4023 (0.4024)  loss_vfl_aux_3: 0.3936 (0.3917)  loss_vfl_aux_4: 0.3896 (0.3888)  loss_vfl_dn_0: 0.3638 (0.3626)  loss_vfl_dn_1: 0.3256 (0.3254)  loss_vfl_dn_2: 0.3205 (0.3205)  loss_vfl_dn_3: 0.3183 (0.3195)  loss_vfl_dn_4: 0.3181 (0.3192)  loss_vfl_dn_5: 0.3179 (0.3192)  loss_vfl_enc_0: 0.5112 (0.5039)  time: 0.4884  data: 0.0103  max mem: 5637
Epoch: [0]  [ 500/1519]  eta: 0:09:01  lr: 0.000004  lr2: 0.000040  loss: 10.7588 (10.8513)  loss_bbox: 0.1388 (0.1340)  loss_bbox_aux_0: 0.1420 (0.1393)  loss_bbox_aux_1: 0.1394 (0.1345)  loss_bbox_aux_2: 0.1395 (0.1340)  loss_bbox_aux_3: 0.1385 (0.1338)  loss_bbox_aux_4: 0.1378 (0.1338)  loss_bbox_dn_0: 0.1638 (0.1641)  loss_bbox_dn_1: 0.1322 (0.1343)  loss_bbox_dn_2: 0.1300 (0.1299)  loss_bbox_dn_3: 0.1290 (0.1284)  loss_bbox_dn_4: 0.1289 (0.1277)  loss_bbox_dn_5: 0.1289 (0.1277)  loss_bbox_enc_0: 0.1606 (0.1584)  loss_giou: 0.3262 (0.3220)  loss_giou_aux_0: 0.3332 (0.3332)  loss_giou_aux_1: 0.3291 (0.3244)  loss_giou_aux_2: 0.3274 (0.3224)  loss_giou_aux_3: 0.3264 (0.3220)  loss_giou_aux_4: 0.3231 (0.3218)  loss_giou_dn_0: 0.3505 (0.3512)  loss_giou_dn_1: 0.2883 (0.2930)  loss_giou_dn_2: 0.2777 (0.2857)  loss_giou_dn_3: 0.2767 (0.2844)  loss_giou_dn_4: 0.2758 (0.2841)  loss_giou_dn_5: 0.2759 (0.2842)  loss_giou_enc_0: 0.3752 (0.3775)  loss_vfl: 0.3890 (0.3883)  loss_vfl_aux_0: 0.4864 (0.4876)  loss_vfl_aux_1: 0.4346 (0.4311)  loss_vfl_aux_2: 0.3985 (0.4032)  loss_vfl_aux_3: 0.3954 (0.3925)  loss_vfl_aux_4: 0.3888 (0.3895)  loss_vfl_dn_0: 0.3612 (0.3628)  loss_vfl_dn_1: 0.3247 (0.3258)  loss_vfl_dn_2: 0.3205 (0.3209)  loss_vfl_dn_3: 0.3194 (0.3200)  loss_vfl_dn_4: 0.3187 (0.3196)  loss_vfl_dn_5: 0.3187 (0.3196)  loss_vfl_enc_0: 0.5066 (0.5043)  time: 0.4969  data: 0.0100  max mem: 5637
Epoch: [0]  [ 600/1519]  eta: 0:08:01  lr: 0.000004  lr2: 0.000040  loss: 10.6873 (10.8398)  loss_bbox: 0.1373 (0.1340)  loss_bbox_aux_0: 0.1404 (0.1389)  loss_bbox_aux_1: 0.1369 (0.1343)  loss_bbox_aux_2: 0.1335 (0.1339)  loss_bbox_aux_3: 0.1376 (0.1338)  loss_bbox_aux_4: 0.1373 (0.1338)  loss_bbox_dn_0: 0.1615 (0.1635)  loss_bbox_dn_1: 0.1277 (0.1337)  loss_bbox_dn_2: 0.1232 (0.1294)  loss_bbox_dn_3: 0.1227 (0.1278)  loss_bbox_dn_4: 0.1224 (0.1271)  loss_bbox_dn_5: 0.1224 (0.1271)  loss_bbox_enc_0: 0.1565 (0.1579)  loss_giou: 0.3311 (0.3223)  loss_giou_aux_0: 0.3383 (0.3330)  loss_giou_aux_1: 0.3307 (0.3245)  loss_giou_aux_2: 0.3290 (0.3226)  loss_giou_aux_3: 0.3295 (0.3222)  loss_giou_aux_4: 0.3291 (0.3221)  loss_giou_dn_0: 0.3468 (0.3511)  loss_giou_dn_1: 0.2886 (0.2929)  loss_giou_dn_2: 0.2834 (0.2857)  loss_giou_dn_3: 0.2818 (0.2844)  loss_giou_dn_4: 0.2810 (0.2841)  loss_giou_dn_5: 0.2811 (0.2841)  loss_giou_enc_0: 0.3675 (0.3771)  loss_vfl: 0.3709 (0.3873)  loss_vfl_aux_0: 0.4960 (0.4866)  loss_vfl_aux_1: 0.4261 (0.4298)  loss_vfl_aux_2: 0.3909 (0.4023)  loss_vfl_aux_3: 0.3786 (0.3916)  loss_vfl_aux_4: 0.3743 (0.3884)  loss_vfl_dn_0: 0.3630 (0.3627)  loss_vfl_dn_1: 0.3270 (0.3258)  loss_vfl_dn_2: 0.3219 (0.3210)  loss_vfl_dn_3: 0.3205 (0.3200)  loss_vfl_dn_4: 0.3196 (0.3197)  loss_vfl_dn_5: 0.3197 (0.3196)  loss_vfl_enc_0: 0.5102 (0.5037)  time: 0.4832  data: 0.0107  max mem: 5637
Epoch: [0]  [ 700/1519]  eta: 0:07:04  lr: 0.000004  lr2: 0.000040  loss: 10.9666 (10.8451)  loss_bbox: 0.1275 (0.1342)  loss_bbox_aux_0: 0.1229 (0.1387)  loss_bbox_aux_1: 0.1198 (0.1344)  loss_bbox_aux_2: 0.1287 (0.1341)  loss_bbox_aux_3: 0.1249 (0.1338)  loss_bbox_aux_4: 0.1275 (0.1340)  loss_bbox_dn_0: 0.1587 (0.1633)  loss_bbox_dn_1: 0.1244 (0.1336)  loss_bbox_dn_2: 0.1184 (0.1293)  loss_bbox_dn_3: 0.1153 (0.1276)  loss_bbox_dn_4: 0.1142 (0.1269)  loss_bbox_dn_5: 0.1142 (0.1269)  loss_bbox_enc_0: 0.1400 (0.1580)  loss_giou: 0.3295 (0.3233)  loss_giou_aux_0: 0.3284 (0.3334)  loss_giou_aux_1: 0.3237 (0.3253)  loss_giou_aux_2: 0.3244 (0.3235)  loss_giou_aux_3: 0.3252 (0.3231)  loss_giou_aux_4: 0.3242 (0.3230)  loss_giou_dn_0: 0.3579 (0.3515)  loss_giou_dn_1: 0.2968 (0.2935)  loss_giou_dn_2: 0.2891 (0.2863)  loss_giou_dn_3: 0.2887 (0.2849)  loss_giou_dn_4: 0.2888 (0.2846)  loss_giou_dn_5: 0.2889 (0.2846)  loss_giou_enc_0: 0.3835 (0.3779)  loss_vfl: 0.3831 (0.3866)  loss_vfl_aux_0: 0.4947 (0.4866)  loss_vfl_aux_1: 0.4250 (0.4291)  loss_vfl_aux_2: 0.4056 (0.4016)  loss_vfl_aux_3: 0.3913 (0.3910)  loss_vfl_aux_4: 0.3832 (0.3877)  loss_vfl_dn_0: 0.3655 (0.3627)  loss_vfl_dn_1: 0.3284 (0.3260)  loss_vfl_dn_2: 0.3238 (0.3212)  loss_vfl_dn_3: 0.3230 (0.3202)  loss_vfl_dn_4: 0.3223 (0.3198)  loss_vfl_dn_5: 0.3224 (0.3198)  loss_vfl_enc_0: 0.5103 (0.5035)  time: 0.4865  data: 0.0098  max mem: 5638
Epoch: [0]  [ 800/1519]  eta: 0:06:11  lr: 0.000004  lr2: 0.000040  loss: 10.7137 (10.8562)  loss_bbox: 0.1331 (0.1343)  loss_bbox_aux_0: 0.1344 (0.1389)  loss_bbox_aux_1: 0.1326 (0.1346)  loss_bbox_aux_2: 0.1304 (0.1341)  loss_bbox_aux_3: 0.1340 (0.1340)  loss_bbox_aux_4: 0.1331 (0.1341)  loss_bbox_dn_0: 0.1598 (0.1634)  loss_bbox_dn_1: 0.1265 (0.1336)  loss_bbox_dn_2: 0.1233 (0.1292)  loss_bbox_dn_3: 0.1230 (0.1275)  loss_bbox_dn_4: 0.1229 (0.1268)  loss_bbox_dn_5: 0.1229 (0.1268)  loss_bbox_enc_0: 0.1628 (0.1583)  loss_giou: 0.3254 (0.3238)  loss_giou_aux_0: 0.3292 (0.3339)  loss_giou_aux_1: 0.3340 (0.3259)  loss_giou_aux_2: 0.3285 (0.3240)  loss_giou_aux_3: 0.3283 (0.3237)  loss_giou_aux_4: 0.3284 (0.3236)  loss_giou_dn_0: 0.3482 (0.3519)  loss_giou_dn_1: 0.2950 (0.2938)  loss_giou_dn_2: 0.2900 (0.2865)  loss_giou_dn_3: 0.2879 (0.2852)  loss_giou_dn_4: 0.2867 (0.2848)  loss_giou_dn_5: 0.2867 (0.2848)  loss_giou_enc_0: 0.3857 (0.3787)  loss_vfl: 0.3861 (0.3873)  loss_vfl_aux_0: 0.4834 (0.4874)  loss_vfl_aux_1: 0.4268 (0.4293)  loss_vfl_aux_2: 0.4001 (0.4021)  loss_vfl_aux_3: 0.3719 (0.3915)  loss_vfl_aux_4: 0.3857 (0.3884)  loss_vfl_dn_0: 0.3630 (0.3627)  loss_vfl_dn_1: 0.3249 (0.3260)  loss_vfl_dn_2: 0.3200 (0.3212)  loss_vfl_dn_3: 0.3188 (0.3202)  loss_vfl_dn_4: 0.3182 (0.3199)  loss_vfl_dn_5: 0.3180 (0.3198)  loss_vfl_enc_0: 0.5007 (0.5043)  time: 0.4893  data: 0.0101  max mem: 5638
Epoch: [0]  [ 900/1519]  eta: 0:05:17  lr: 0.000004  lr2: 0.000040  loss: 10.6146 (10.8398)  loss_bbox: 0.1278 (0.1341)  loss_bbox_aux_0: 0.1326 (0.1385)  loss_bbox_aux_1: 0.1281 (0.1345)  loss_bbox_aux_2: 0.1270 (0.1339)  loss_bbox_aux_3: 0.1268 (0.1338)  loss_bbox_aux_4: 0.1271 (0.1339)  loss_bbox_dn_0: 0.1562 (0.1630)  loss_bbox_dn_1: 0.1293 (0.1333)  loss_bbox_dn_2: 0.1246 (0.1290)  loss_bbox_dn_3: 0.1225 (0.1273)  loss_bbox_dn_4: 0.1213 (0.1265)  loss_bbox_dn_5: 0.1213 (0.1265)  loss_bbox_enc_0: 0.1488 (0.1581)  loss_giou: 0.3219 (0.3234)  loss_giou_aux_0: 0.3227 (0.3333)  loss_giou_aux_1: 0.3163 (0.3254)  loss_giou_aux_2: 0.3150 (0.3236)  loss_giou_aux_3: 0.3126 (0.3232)  loss_giou_aux_4: 0.3219 (0.3231)  loss_giou_dn_0: 0.3431 (0.3513)  loss_giou_dn_1: 0.2811 (0.2932)  loss_giou_dn_2: 0.2758 (0.2860)  loss_giou_dn_3: 0.2742 (0.2846)  loss_giou_dn_4: 0.2736 (0.2842)  loss_giou_dn_5: 0.2736 (0.2843)  loss_giou_enc_0: 0.3664 (0.3782)  loss_vfl: 0.3738 (0.3866)  loss_vfl_aux_0: 0.4684 (0.4869)  loss_vfl_aux_1: 0.4123 (0.4284)  loss_vfl_aux_2: 0.3866 (0.4012)  loss_vfl_aux_3: 0.3796 (0.3908)  loss_vfl_aux_4: 0.3767 (0.3878)  loss_vfl_dn_0: 0.3597 (0.3623)  loss_vfl_dn_1: 0.3215 (0.3257)  loss_vfl_dn_2: 0.3165 (0.3209)  loss_vfl_dn_3: 0.3144 (0.3199)  loss_vfl_dn_4: 0.3141 (0.3195)  loss_vfl_dn_5: 0.3140 (0.3195)  loss_vfl_enc_0: 0.4933 (0.5041)  time: 0.4912  data: 0.0100  max mem: 5638
Epoch: [0]  [1000/1519]  eta: 0:04:25  lr: 0.000004  lr2: 0.000040  loss: 10.5968 (10.8356)  loss_bbox: 0.1323 (0.1341)  loss_bbox_aux_0: 0.1370 (0.1386)  loss_bbox_aux_1: 0.1341 (0.1346)  loss_bbox_aux_2: 0.1345 (0.1340)  loss_bbox_aux_3: 0.1326 (0.1339)  loss_bbox_aux_4: 0.1319 (0.1340)  loss_bbox_dn_0: 0.1544 (0.1629)  loss_bbox_dn_1: 0.1281 (0.1332)  loss_bbox_dn_2: 0.1236 (0.1289)  loss_bbox_dn_3: 0.1221 (0.1272)  loss_bbox_dn_4: 0.1214 (0.1264)  loss_bbox_dn_5: 0.1214 (0.1264)  loss_bbox_enc_0: 0.1595 (0.1583)  loss_giou: 0.3171 (0.3231)  loss_giou_aux_0: 0.3272 (0.3329)  loss_giou_aux_1: 0.3209 (0.3252)  loss_giou_aux_2: 0.3175 (0.3233)  loss_giou_aux_3: 0.3174 (0.3229)  loss_giou_aux_4: 0.3180 (0.3229)  loss_giou_dn_0: 0.3433 (0.3511)  loss_giou_dn_1: 0.2884 (0.2931)  loss_giou_dn_2: 0.2833 (0.2859)  loss_giou_dn_3: 0.2828 (0.2845)  loss_giou_dn_4: 0.2826 (0.2841)  loss_giou_dn_5: 0.2828 (0.2842)  loss_giou_enc_0: 0.3768 (0.3778)  loss_vfl: 0.4004 (0.3866)  loss_vfl_aux_0: 0.4717 (0.4866)  loss_vfl_aux_1: 0.4272 (0.4279)  loss_vfl_aux_2: 0.4108 (0.4009)  loss_vfl_aux_3: 0.3977 (0.3908)  loss_vfl_aux_4: 0.4011 (0.3877)  loss_vfl_dn_0: 0.3588 (0.3622)  loss_vfl_dn_1: 0.3234 (0.3257)  loss_vfl_dn_2: 0.3185 (0.3209)  loss_vfl_dn_3: 0.3171 (0.3199)  loss_vfl_dn_4: 0.3171 (0.3195)  loss_vfl_dn_5: 0.3172 (0.3195)  loss_vfl_enc_0: 0.4935 (0.5041)  time: 0.4898  data: 0.0107  max mem: 5639
Epoch: [0]  [1100/1519]  eta: 0:03:33  lr: 0.000004  lr2: 0.000040  loss: 10.5734 (10.8266)  loss_bbox: 0.1347 (0.1342)  loss_bbox_aux_0: 0.1414 (0.1388)  loss_bbox_aux_1: 0.1332 (0.1347)  loss_bbox_aux_2: 0.1311 (0.1341)  loss_bbox_aux_3: 0.1349 (0.1340)  loss_bbox_aux_4: 0.1347 (0.1340)  loss_bbox_dn_0: 0.1693 (0.1632)  loss_bbox_dn_1: 0.1378 (0.1334)  loss_bbox_dn_2: 0.1343 (0.1290)  loss_bbox_dn_3: 0.1317 (0.1273)  loss_bbox_dn_4: 0.1301 (0.1264)  loss_bbox_dn_5: 0.1301 (0.1264)  loss_bbox_enc_0: 0.1604 (0.1585)  loss_giou: 0.3040 (0.3227)  loss_giou_aux_0: 0.3237 (0.3327)  loss_giou_aux_1: 0.3207 (0.3249)  loss_giou_aux_2: 0.3061 (0.3230)  loss_giou_aux_3: 0.3043 (0.3225)  loss_giou_aux_4: 0.3045 (0.3225)  loss_giou_dn_0: 0.3425 (0.3507)  loss_giou_dn_1: 0.2869 (0.2927)  loss_giou_dn_2: 0.2795 (0.2855)  loss_giou_dn_3: 0.2746 (0.2841)  loss_giou_dn_4: 0.2733 (0.2837)  loss_giou_dn_5: 0.2733 (0.2837)  loss_giou_enc_0: 0.3760 (0.3774)  loss_vfl: 0.3822 (0.3861)  loss_vfl_aux_0: 0.4599 (0.4857)  loss_vfl_aux_1: 0.4134 (0.4273)  loss_vfl_aux_2: 0.4008 (0.4004)  loss_vfl_aux_3: 0.3834 (0.3904)  loss_vfl_aux_4: 0.3830 (0.3873)  loss_vfl_dn_0: 0.3613 (0.3620)  loss_vfl_dn_1: 0.3184 (0.3254)  loss_vfl_dn_2: 0.3123 (0.3206)  loss_vfl_dn_3: 0.3099 (0.3196)  loss_vfl_dn_4: 0.3093 (0.3192)  loss_vfl_dn_5: 0.3092 (0.3192)  loss_vfl_enc_0: 0.4880 (0.5034)  time: 0.4882  data: 0.0107  max mem: 5639
Epoch: [0]  [1200/1519]  eta: 0:02:42  lr: 0.000004  lr2: 0.000040  loss: 10.8896 (10.8231)  loss_bbox: 0.1387 (0.1342)  loss_bbox_aux_0: 0.1400 (0.1388)  loss_bbox_aux_1: 0.1394 (0.1348)  loss_bbox_aux_2: 0.1397 (0.1341)  loss_bbox_aux_3: 0.1364 (0.1340)  loss_bbox_aux_4: 0.1376 (0.1340)  loss_bbox_dn_0: 0.1681 (0.1630)  loss_bbox_dn_1: 0.1415 (0.1332)  loss_bbox_dn_2: 0.1365 (0.1289)  loss_bbox_dn_3: 0.1333 (0.1271)  loss_bbox_dn_4: 0.1323 (0.1262)  loss_bbox_dn_5: 0.1323 (0.1262)  loss_bbox_enc_0: 0.1577 (0.1585)  loss_giou: 0.3176 (0.3229)  loss_giou_aux_0: 0.3328 (0.3329)  loss_giou_aux_1: 0.3257 (0.3252)  loss_giou_aux_2: 0.3242 (0.3233)  loss_giou_aux_3: 0.3175 (0.3227)  loss_giou_aux_4: 0.3177 (0.3227)  loss_giou_dn_0: 0.3486 (0.3507)  loss_giou_dn_1: 0.2891 (0.2927)  loss_giou_dn_2: 0.2818 (0.2855)  loss_giou_dn_3: 0.2809 (0.2840)  loss_giou_dn_4: 0.2808 (0.2836)  loss_giou_dn_5: 0.2808 (0.2836)  loss_giou_enc_0: 0.3802 (0.3777)  loss_vfl: 0.3766 (0.3859)  loss_vfl_aux_0: 0.4659 (0.4850)  loss_vfl_aux_1: 0.4131 (0.4263)  loss_vfl_aux_2: 0.3885 (0.3998)  loss_vfl_aux_3: 0.3789 (0.3900)  loss_vfl_aux_4: 0.3756 (0.3870)  loss_vfl_dn_0: 0.3628 (0.3619)  loss_vfl_dn_1: 0.3277 (0.3254)  loss_vfl_dn_2: 0.3232 (0.3206)  loss_vfl_dn_3: 0.3222 (0.3196)  loss_vfl_dn_4: 0.3218 (0.3192)  loss_vfl_dn_5: 0.3218 (0.3191)  loss_vfl_enc_0: 0.4916 (0.5029)  time: 0.5070  data: 0.0106  max mem: 5639
Epoch: [0]  [1300/1519]  eta: 0:01:51  lr: 0.000004  lr2: 0.000040  loss: 10.7425 (10.8203)  loss_bbox: 0.1297 (0.1342)  loss_bbox_aux_0: 0.1339 (0.1388)  loss_bbox_aux_1: 0.1323 (0.1349)  loss_bbox_aux_2: 0.1286 (0.1341)  loss_bbox_aux_3: 0.1293 (0.1340)  loss_bbox_aux_4: 0.1297 (0.1340)  loss_bbox_dn_0: 0.1547 (0.1627)  loss_bbox_dn_1: 0.1286 (0.1330)  loss_bbox_dn_2: 0.1250 (0.1287)  loss_bbox_dn_3: 0.1194 (0.1269)  loss_bbox_dn_4: 0.1178 (0.1260)  loss_bbox_dn_5: 0.1178 (0.1260)  loss_bbox_enc_0: 0.1495 (0.1584)  loss_giou: 0.3289 (0.3232)  loss_giou_aux_0: 0.3418 (0.3331)  loss_giou_aux_1: 0.3333 (0.3255)  loss_giou_aux_2: 0.3304 (0.3236)  loss_giou_aux_3: 0.3314 (0.3230)  loss_giou_aux_4: 0.3290 (0.3230)  loss_giou_dn_0: 0.3511 (0.3507)  loss_giou_dn_1: 0.2978 (0.2928)  loss_giou_dn_2: 0.2897 (0.2855)  loss_giou_dn_3: 0.2883 (0.2841)  loss_giou_dn_4: 0.2884 (0.2837)  loss_giou_dn_5: 0.2885 (0.2837)  loss_giou_enc_0: 0.3889 (0.3779)  loss_vfl: 0.3766 (0.3856)  loss_vfl_aux_0: 0.4551 (0.4840)  loss_vfl_aux_1: 0.4064 (0.4253)  loss_vfl_aux_2: 0.3806 (0.3992)  loss_vfl_aux_3: 0.3753 (0.3895)  loss_vfl_aux_4: 0.3725 (0.3867)  loss_vfl_dn_0: 0.3625 (0.3619)  loss_vfl_dn_1: 0.3256 (0.3255)  loss_vfl_dn_2: 0.3228 (0.3207)  loss_vfl_dn_3: 0.3229 (0.3197)  loss_vfl_dn_4: 0.3225 (0.3193)  loss_vfl_dn_5: 0.3224 (0.3193)  loss_vfl_enc_0: 0.4873 (0.5022)  time: 0.4862  data: 0.0099  max mem: 5639
Epoch: [0]  [1400/1519]  eta: 0:01:00  lr: 0.000004  lr2: 0.000040  loss: 10.6369 (10.8199)  loss_bbox: 0.1317 (0.1340)  loss_bbox_aux_0: 0.1338 (0.1386)  loss_bbox_aux_1: 0.1331 (0.1349)  loss_bbox_aux_2: 0.1320 (0.1340)  loss_bbox_aux_3: 0.1317 (0.1339)  loss_bbox_aux_4: 0.1314 (0.1339)  loss_bbox_dn_0: 0.1575 (0.1627)  loss_bbox_dn_1: 0.1321 (0.1330)  loss_bbox_dn_2: 0.1279 (0.1287)  loss_bbox_dn_3: 0.1268 (0.1268)  loss_bbox_dn_4: 0.1253 (0.1260)  loss_bbox_dn_5: 0.1253 (0.1260)  loss_bbox_enc_0: 0.1512 (0.1582)  loss_giou: 0.3139 (0.3231)  loss_giou_aux_0: 0.3242 (0.3329)  loss_giou_aux_1: 0.3209 (0.3255)  loss_giou_aux_2: 0.3157 (0.3235)  loss_giou_aux_3: 0.3128 (0.3230)  loss_giou_aux_4: 0.3135 (0.3229)  loss_giou_dn_0: 0.3507 (0.3507)  loss_giou_dn_1: 0.2941 (0.2928)  loss_giou_dn_2: 0.2870 (0.2855)  loss_giou_dn_3: 0.2839 (0.2841)  loss_giou_dn_4: 0.2836 (0.2837)  loss_giou_dn_5: 0.2837 (0.2837)  loss_giou_enc_0: 0.3704 (0.3779)  loss_vfl: 0.3852 (0.3861)  loss_vfl_aux_0: 0.4950 (0.4839)  loss_vfl_aux_1: 0.4262 (0.4251)  loss_vfl_aux_2: 0.3986 (0.3994)  loss_vfl_aux_3: 0.3838 (0.3899)  loss_vfl_aux_4: 0.3839 (0.3871)  loss_vfl_dn_0: 0.3566 (0.3618)  loss_vfl_dn_1: 0.3209 (0.3254)  loss_vfl_dn_2: 0.3160 (0.3207)  loss_vfl_dn_3: 0.3155 (0.3197)  loss_vfl_dn_4: 0.3154 (0.3192)  loss_vfl_dn_5: 0.3153 (0.3192)  loss_vfl_enc_0: 0.4991 (0.5020)  time: 0.4871  data: 0.0096  max mem: 5639
Epoch: [0]  [1500/1519]  eta: 0:00:09  lr: 0.000004  lr2: 0.000040  loss: 10.3929 (10.8182)  loss_bbox: 0.1263 (0.1342)  loss_bbox_aux_0: 0.1250 (0.1387)  loss_bbox_aux_1: 0.1291 (0.1350)  loss_bbox_aux_2: 0.1237 (0.1341)  loss_bbox_aux_3: 0.1222 (0.1340)  loss_bbox_aux_4: 0.1263 (0.1340)  loss_bbox_dn_0: 0.1509 (0.1627)  loss_bbox_dn_1: 0.1217 (0.1331)  loss_bbox_dn_2: 0.1186 (0.1288)  loss_bbox_dn_3: 0.1153 (0.1269)  loss_bbox_dn_4: 0.1133 (0.1260)  loss_bbox_dn_5: 0.1133 (0.1260)  loss_bbox_enc_0: 0.1499 (0.1583)  loss_giou: 0.3031 (0.3231)  loss_giou_aux_0: 0.3100 (0.3327)  loss_giou_aux_1: 0.3067 (0.3254)  loss_giou_aux_2: 0.3008 (0.3234)  loss_giou_aux_3: 0.2994 (0.3228)  loss_giou_aux_4: 0.3027 (0.3229)  loss_giou_dn_0: 0.3385 (0.3504)  loss_giou_dn_1: 0.2794 (0.2926)  loss_giou_dn_2: 0.2700 (0.2854)  loss_giou_dn_3: 0.2681 (0.2840)  loss_giou_dn_4: 0.2677 (0.2835)  loss_giou_dn_5: 0.2678 (0.2836)  loss_giou_enc_0: 0.3688 (0.3777)  loss_vfl: 0.3633 (0.3861)  loss_vfl_aux_0: 0.4840 (0.4836)  loss_vfl_aux_1: 0.4119 (0.4250)  loss_vfl_aux_2: 0.3847 (0.3995)  loss_vfl_aux_3: 0.3714 (0.3900)  loss_vfl_aux_4: 0.3625 (0.3871)  loss_vfl_dn_0: 0.3543 (0.3617)  loss_vfl_dn_1: 0.3177 (0.3254)  loss_vfl_dn_2: 0.3130 (0.3206)  loss_vfl_dn_3: 0.3122 (0.3196)  loss_vfl_dn_4: 0.3125 (0.3192)  loss_vfl_dn_5: 0.3124 (0.3192)  loss_vfl_enc_0: 0.4889 (0.5019)  time: 0.4619  data: 0.0095  max mem: 5639
Epoch: [0]  [1518/1519]  eta: 0:00:00  lr: 0.000004  lr2: 0.000040  loss: 10.6744 (10.8155)  loss_bbox: 0.1293 (0.1342)  loss_bbox_aux_0: 0.1329 (0.1387)  loss_bbox_aux_1: 0.1302 (0.1350)  loss_bbox_aux_2: 0.1312 (0.1341)  loss_bbox_aux_3: 0.1294 (0.1340)  loss_bbox_aux_4: 0.1293 (0.1340)  loss_bbox_dn_0: 0.1594 (0.1626)  loss_bbox_dn_1: 0.1339 (0.1330)  loss_bbox_dn_2: 0.1302 (0.1287)  loss_bbox_dn_3: 0.1272 (0.1268)  loss_bbox_dn_4: 0.1261 (0.1260)  loss_bbox_dn_5: 0.1262 (0.1260)  loss_bbox_enc_0: 0.1499 (0.1583)  loss_giou: 0.3116 (0.3230)  loss_giou_aux_0: 0.3198 (0.3326)  loss_giou_aux_1: 0.3114 (0.3253)  loss_giou_aux_2: 0.3130 (0.3233)  loss_giou_aux_3: 0.3124 (0.3228)  loss_giou_aux_4: 0.3116 (0.3228)  loss_giou_dn_0: 0.3388 (0.3503)  loss_giou_dn_1: 0.2824 (0.2926)  loss_giou_dn_2: 0.2777 (0.2853)  loss_giou_dn_3: 0.2768 (0.2839)  loss_giou_dn_4: 0.2763 (0.2835)  loss_giou_dn_5: 0.2765 (0.2835)  loss_giou_enc_0: 0.3660 (0.3776)  loss_vfl: 0.3714 (0.3859)  loss_vfl_aux_0: 0.4772 (0.4836)  loss_vfl_aux_1: 0.4081 (0.4248)  loss_vfl_aux_2: 0.3888 (0.3994)  loss_vfl_aux_3: 0.3761 (0.3899)  loss_vfl_aux_4: 0.3714 (0.3869)  loss_vfl_dn_0: 0.3552 (0.3616)  loss_vfl_dn_1: 0.3177 (0.3253)  loss_vfl_dn_2: 0.3151 (0.3206)  loss_vfl_dn_3: 0.3143 (0.3196)  loss_vfl_dn_4: 0.3132 (0.3191)  loss_vfl_dn_5: 0.3134 (0.3191)  loss_vfl_enc_0: 0.5026 (0.5019)  time: 0.4351  data: 0.0087  max mem: 5639
Epoch: [0] Total time: 0:12:49 (0.5063 s / it)
Averaged stats: lr: 0.000004  lr2: 0.000040  loss: 10.6744 (10.8155)  loss_bbox: 0.1293 (0.1342)  loss_bbox_aux_0: 0.1329 (0.1387)  loss_bbox_aux_1: 0.1302 (0.1350)  loss_bbox_aux_2: 0.1312 (0.1341)  loss_bbox_aux_3: 0.1294 (0.1340)  loss_bbox_aux_4: 0.1293 (0.1340)  loss_bbox_dn_0: 0.1594 (0.1626)  loss_bbox_dn_1: 0.1339 (0.1330)  loss_bbox_dn_2: 0.1302 (0.1287)  loss_bbox_dn_3: 0.1272 (0.1268)  loss_bbox_dn_4: 0.1261 (0.1260)  loss_bbox_dn_5: 0.1262 (0.1260)  loss_bbox_enc_0: 0.1499 (0.1583)  loss_giou: 0.3116 (0.3230)  loss_giou_aux_0: 0.3198 (0.3326)  loss_giou_aux_1: 0.3114 (0.3253)  loss_giou_aux_2: 0.3130 (0.3233)  loss_giou_aux_3: 0.3124 (0.3228)  loss_giou_aux_4: 0.3116 (0.3228)  loss_giou_dn_0: 0.3388 (0.3503)  loss_giou_dn_1: 0.2824 (0.2926)  loss_giou_dn_2: 0.2777 (0.2853)  loss_giou_dn_3: 0.2768 (0.2839)  loss_giou_dn_4: 0.2763 (0.2835)  loss_giou_dn_5: 0.2765 (0.2835)  loss_giou_enc_0: 0.3660 (0.3776)  loss_vfl: 0.3714 (0.3859)  loss_vfl_aux_0: 0.4772 (0.4836)  loss_vfl_aux_1: 0.4081 (0.4248)  loss_vfl_aux_2: 0.3888 (0.3994)  loss_vfl_aux_3: 0.3761 (0.3899)  loss_vfl_aux_4: 0.3714 (0.3869)  loss_vfl_dn_0: 0.3552 (0.3616)  loss_vfl_dn_1: 0.3177 (0.3253)  loss_vfl_dn_2: 0.3151 (0.3206)  loss_vfl_dn_3: 0.3143 (0.3196)  loss_vfl_dn_4: 0.3132 (0.3191)  loss_vfl_dn_5: 0.3134 (0.3191)  loss_vfl_enc_0: 0.5026 (0.5019)
Test:  [  0/165]  eta: 0:06:32    time: 2.3817  data: 1.8743  max mem: 5639
Test:  [ 10/165]  eta: 0:01:06    time: 0.4290  data: 0.1939  max mem: 5639
Test:  [ 20/165]  eta: 0:00:53    time: 0.2699  data: 0.0321  max mem: 5639
Test:  [ 30/165]  eta: 0:00:43    time: 0.2622  data: 0.0256  max mem: 5639
Test:  [ 40/165]  eta: 0:00:37    time: 0.2244  data: 0.0233  max mem: 5639
Test:  [ 50/165]  eta: 0:00:33    time: 0.2520  data: 0.0325  max mem: 5639
Test:  [ 60/165]  eta: 0:00:29    time: 0.2464  data: 0.0243  max mem: 5639
Test:  [ 70/165]  eta: 0:00:26    time: 0.2574  data: 0.0271  max mem: 5639
Test:  [ 80/165]  eta: 0:00:23    time: 0.2694  data: 0.0358  max mem: 5639
Test:  [ 90/165]  eta: 0:00:20    time: 0.2302  data: 0.0258  max mem: 5639
Test:  [100/165]  eta: 0:00:17    time: 0.2526  data: 0.0514  max mem: 5639
Test:  [110/165]  eta: 0:00:14    time: 0.2523  data: 0.0496  max mem: 5639
Test:  [120/165]  eta: 0:00:11    time: 0.2271  data: 0.0248  max mem: 5639
Test:  [130/165]  eta: 0:00:09    time: 0.2543  data: 0.0321  max mem: 5639
Test:  [140/165]  eta: 0:00:06    time: 0.2395  data: 0.0213  max mem: 5639
Test:  [150/165]  eta: 0:00:03    time: 0.2378  data: 0.0447  max mem: 5639
Test:  [160/165]  eta: 0:00:01    time: 0.2364  data: 0.0449  max mem: 5639
Test:  [164/165]  eta: 0:00:00    time: 0.2230  data: 0.0374  max mem: 5639
Test: Total time: 0:00:42 (0.2575 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=27.07s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
best_stat: {'epoch': 0, 'coco_eval_bbox': 0.4708596759809729}
Epoch: [1]  [   0/1519]  eta: 3:44:08  lr: 0.000004  lr2: 0.000040  loss: 10.2913 (10.2913)  loss_bbox: 0.1144 (0.1144)  loss_bbox_aux_0: 0.1239 (0.1239)  loss_bbox_aux_1: 0.1182 (0.1182)  loss_bbox_aux_2: 0.1163 (0.1163)  loss_bbox_aux_3: 0.1147 (0.1147)  loss_bbox_aux_4: 0.1144 (0.1144)  loss_bbox_dn_0: 0.1345 (0.1345)  loss_bbox_dn_1: 0.1055 (0.1055)  loss_bbox_dn_2: 0.1020 (0.1020)  loss_bbox_dn_3: 0.1010 (0.1010)  loss_bbox_dn_4: 0.1006 (0.1006)  loss_bbox_dn_5: 0.1007 (0.1007)  loss_bbox_enc_0: 0.1586 (0.1586)  loss_giou: 0.3260 (0.3260)  loss_giou_aux_0: 0.3354 (0.3354)  loss_giou_aux_1: 0.3291 (0.3291)  loss_giou_aux_2: 0.3274 (0.3274)  loss_giou_aux_3: 0.3249 (0.3249)  loss_giou_aux_4: 0.3259 (0.3259)  loss_giou_dn_0: 0.3437 (0.3437)  loss_giou_dn_1: 0.2808 (0.2808)  loss_giou_dn_2: 0.2751 (0.2751)  loss_giou_dn_3: 0.2740 (0.2740)  loss_giou_dn_4: 0.2740 (0.2740)  loss_giou_dn_5: 0.2743 (0.2743)  loss_giou_enc_0: 0.3864 (0.3864)  loss_vfl: 0.3509 (0.3509)  loss_vfl_aux_0: 0.4721 (0.4721)  loss_vfl_aux_1: 0.3784 (0.3784)  loss_vfl_aux_2: 0.3570 (0.3570)  loss_vfl_aux_3: 0.3523 (0.3523)  loss_vfl_aux_4: 0.3512 (0.3512)  loss_vfl_dn_0: 0.3644 (0.3644)  loss_vfl_dn_1: 0.3233 (0.3233)  loss_vfl_dn_2: 0.3178 (0.3178)  loss_vfl_dn_3: 0.3168 (0.3168)  loss_vfl_dn_4: 0.3167 (0.3167)  loss_vfl_dn_5: 0.3167 (0.3167)  loss_vfl_enc_0: 0.4917 (0.4917)  time: 8.8536  data: 5.6082  max mem: 5639
Epoch: [1]  [ 100/1519]  eta: 0:14:20  lr: 0.000004  lr2: 0.000040  loss: 10.6329 (10.7519)  loss_bbox: 0.1298 (0.1340)  loss_bbox_aux_0: 0.1327 (0.1389)  loss_bbox_aux_1: 0.1288 (0.1350)  loss_bbox_aux_2: 0.1308 (0.1342)  loss_bbox_aux_3: 0.1300 (0.1346)  loss_bbox_aux_4: 0.1307 (0.1335)  loss_bbox_dn_0: 0.1571 (0.1608)  loss_bbox_dn_1: 0.1269 (0.1317)  loss_bbox_dn_2: 0.1248 (0.1276)  loss_bbox_dn_3: 0.1203 (0.1252)  loss_bbox_dn_4: 0.1188 (0.1240)  loss_bbox_dn_5: 0.1188 (0.1240)  loss_bbox_enc_0: 0.1507 (0.1572)  loss_giou: 0.3041 (0.3231)  loss_giou_aux_0: 0.3141 (0.3327)  loss_giou_aux_1: 0.3079 (0.3256)  loss_giou_aux_2: 0.3034 (0.3238)  loss_giou_aux_3: 0.3040 (0.3231)  loss_giou_aux_4: 0.3041 (0.3230)  loss_giou_dn_0: 0.3446 (0.3495)  loss_giou_dn_1: 0.2814 (0.2924)  loss_giou_dn_2: 0.2745 (0.2854)  loss_giou_dn_3: 0.2716 (0.2838)  loss_giou_dn_4: 0.2709 (0.2832)  loss_giou_dn_5: 0.2709 (0.2833)  loss_giou_enc_0: 0.3664 (0.3794)  loss_vfl: 0.3633 (0.3827)  loss_vfl_aux_0: 0.4789 (0.4739)  loss_vfl_aux_1: 0.4030 (0.4128)  loss_vfl_aux_2: 0.3792 (0.3932)  loss_vfl_aux_3: 0.3676 (0.3862)  loss_vfl_aux_4: 0.3652 (0.3838)  loss_vfl_dn_0: 0.3577 (0.3591)  loss_vfl_dn_1: 0.3200 (0.3238)  loss_vfl_dn_2: 0.3160 (0.3192)  loss_vfl_dn_3: 0.3144 (0.3181)  loss_vfl_dn_4: 0.3137 (0.3175)  loss_vfl_dn_5: 0.3138 (0.3176)  loss_vfl_enc_0: 0.4971 (0.4950)  time: 0.5032  data: 0.0097  max mem: 5639
Epoch: [1]  [ 200/1519]  eta: 0:12:15  lr: 0.000004  lr2: 0.000040  loss: 10.4677 (10.7079)  loss_bbox: 0.1258 (0.1335)  loss_bbox_aux_0: 0.1345 (0.1386)  loss_bbox_aux_1: 0.1300 (0.1350)  loss_bbox_aux_2: 0.1333 (0.1343)  loss_bbox_aux_3: 0.1330 (0.1346)  loss_bbox_aux_4: 0.1258 (0.1332)  loss_bbox_dn_0: 0.1481 (0.1607)  loss_bbox_dn_1: 0.1205 (0.1318)  loss_bbox_dn_2: 0.1173 (0.1277)  loss_bbox_dn_3: 0.1175 (0.1255)  loss_bbox_dn_4: 0.1167 (0.1244)  loss_bbox_dn_5: 0.1167 (0.1244)  loss_bbox_enc_0: 0.1478 (0.1568)  loss_giou: 0.3183 (0.3204)  loss_giou_aux_0: 0.3275 (0.3300)  loss_giou_aux_1: 0.3183 (0.3228)  loss_giou_aux_2: 0.3175 (0.3213)  loss_giou_aux_3: 0.3190 (0.3207)  loss_giou_aux_4: 0.3182 (0.3203)  loss_giou_dn_0: 0.3390 (0.3467)  loss_giou_dn_1: 0.2833 (0.2900)  loss_giou_dn_2: 0.2780 (0.2827)  loss_giou_dn_3: 0.2771 (0.2811)  loss_giou_dn_4: 0.2763 (0.2806)  loss_giou_dn_5: 0.2763 (0.2806)  loss_giou_enc_0: 0.3750 (0.3756)  loss_vfl: 0.3665 (0.3819)  loss_vfl_aux_0: 0.4559 (0.4729)  loss_vfl_aux_1: 0.3994 (0.4131)  loss_vfl_aux_2: 0.3831 (0.3918)  loss_vfl_aux_3: 0.3777 (0.3840)  loss_vfl_aux_4: 0.3677 (0.3827)  loss_vfl_dn_0: 0.3572 (0.3591)  loss_vfl_dn_1: 0.3239 (0.3236)  loss_vfl_dn_2: 0.3196 (0.3190)  loss_vfl_dn_3: 0.3192 (0.3179)  loss_vfl_dn_4: 0.3185 (0.3175)  loss_vfl_dn_5: 0.3187 (0.3175)  loss_vfl_enc_0: 0.4799 (0.4936)  time: 0.5639  data: 0.0104  max mem: 5639
Epoch: [1]  [ 300/1519]  eta: 0:11:27  lr: 0.000004  lr2: 0.000040  loss: 10.6428 (10.7116)  loss_bbox: 0.1309 (0.1335)  loss_bbox_aux_0: 0.1365 (0.1387)  loss_bbox_aux_1: 0.1337 (0.1349)  loss_bbox_aux_2: 0.1323 (0.1346)  loss_bbox_aux_3: 0.1314 (0.1349)  loss_bbox_aux_4: 0.1309 (0.1334)  loss_bbox_dn_0: 0.1579 (0.1612)  loss_bbox_dn_1: 0.1306 (0.1322)  loss_bbox_dn_2: 0.1270 (0.1281)  loss_bbox_dn_3: 0.1244 (0.1259)  loss_bbox_dn_4: 0.1241 (0.1247)  loss_bbox_dn_5: 0.1241 (0.1248)  loss_bbox_enc_0: 0.1572 (0.1571)  loss_giou: 0.3163 (0.3191)  loss_giou_aux_0: 0.3251 (0.3293)  loss_giou_aux_1: 0.3185 (0.3219)  loss_giou_aux_2: 0.3171 (0.3202)  loss_giou_aux_3: 0.3169 (0.3196)  loss_giou_aux_4: 0.3163 (0.3193)  loss_giou_dn_0: 0.3439 (0.3464)  loss_giou_dn_1: 0.2861 (0.2895)  loss_giou_dn_2: 0.2771 (0.2823)  loss_giou_dn_3: 0.2770 (0.2807)  loss_giou_dn_4: 0.2770 (0.2801)  loss_giou_dn_5: 0.2768 (0.2802)  loss_giou_enc_0: 0.3695 (0.3754)  loss_vfl: 0.3714 (0.3837)  loss_vfl_aux_0: 0.4638 (0.4722)  loss_vfl_aux_1: 0.4104 (0.4144)  loss_vfl_aux_2: 0.3842 (0.3936)  loss_vfl_aux_3: 0.3760 (0.3858)  loss_vfl_aux_4: 0.3728 (0.3843)  loss_vfl_dn_0: 0.3615 (0.3593)  loss_vfl_dn_1: 0.3223 (0.3237)  loss_vfl_dn_2: 0.3177 (0.3191)  loss_vfl_dn_3: 0.3176 (0.3180)  loss_vfl_dn_4: 0.3174 (0.3175)  loss_vfl_dn_5: 0.3174 (0.3175)  loss_vfl_enc_0: 0.4842 (0.4942)  time: 0.4982  data: 0.0103  max mem: 5639
Epoch: [1]  [ 400/1519]  eta: 0:10:24  lr: 0.000004  lr2: 0.000040  loss: 10.5891 (10.6917)  loss_bbox: 0.1308 (0.1332)  loss_bbox_aux_0: 0.1315 (0.1383)  loss_bbox_aux_1: 0.1276 (0.1344)  loss_bbox_aux_2: 0.1301 (0.1339)  loss_bbox_aux_3: 0.1306 (0.1342)  loss_bbox_aux_4: 0.1308 (0.1331)  loss_bbox_dn_0: 0.1501 (0.1603)  loss_bbox_dn_1: 0.1186 (0.1313)  loss_bbox_dn_2: 0.1143 (0.1272)  loss_bbox_dn_3: 0.1116 (0.1249)  loss_bbox_dn_4: 0.1112 (0.1238)  loss_bbox_dn_5: 0.1112 (0.1238)  loss_bbox_enc_0: 0.1525 (0.1565)  loss_giou: 0.3156 (0.3195)  loss_giou_aux_0: 0.3258 (0.3295)  loss_giou_aux_1: 0.3166 (0.3223)  loss_giou_aux_2: 0.3144 (0.3203)  loss_giou_aux_3: 0.3150 (0.3198)  loss_giou_aux_4: 0.3157 (0.3195)  loss_giou_dn_0: 0.3443 (0.3460)  loss_giou_dn_1: 0.2874 (0.2892)  loss_giou_dn_2: 0.2787 (0.2821)  loss_giou_dn_3: 0.2782 (0.2804)  loss_giou_dn_4: 0.2777 (0.2799)  loss_giou_dn_5: 0.2777 (0.2799)  loss_giou_enc_0: 0.3777 (0.3754)  loss_vfl: 0.3826 (0.3822)  loss_vfl_aux_0: 0.4681 (0.4712)  loss_vfl_aux_1: 0.4135 (0.4129)  loss_vfl_aux_2: 0.3987 (0.3926)  loss_vfl_aux_3: 0.3898 (0.3844)  loss_vfl_aux_4: 0.3859 (0.3828)  loss_vfl_dn_0: 0.3600 (0.3591)  loss_vfl_dn_1: 0.3261 (0.3235)  loss_vfl_dn_2: 0.3207 (0.3189)  loss_vfl_dn_3: 0.3199 (0.3177)  loss_vfl_dn_4: 0.3193 (0.3173)  loss_vfl_dn_5: 0.3189 (0.3173)  loss_vfl_enc_0: 0.4919 (0.4933)  time: 0.4988  data: 0.0098  max mem: 5639
Epoch: [1]  [ 500/1519]  eta: 0:09:29  lr: 0.000004  lr2: 0.000040  loss: 10.8227 (10.6791)  loss_bbox: 0.1402 (0.1335)  loss_bbox_aux_0: 0.1410 (0.1386)  loss_bbox_aux_1: 0.1383 (0.1345)  loss_bbox_aux_2: 0.1388 (0.1339)  loss_bbox_aux_3: 0.1395 (0.1342)  loss_bbox_aux_4: 0.1402 (0.1334)  loss_bbox_dn_0: 0.1750 (0.1607)  loss_bbox_dn_1: 0.1446 (0.1317)  loss_bbox_dn_2: 0.1379 (0.1275)  loss_bbox_dn_3: 0.1340 (0.1251)  loss_bbox_dn_4: 0.1329 (0.1240)  loss_bbox_dn_5: 0.1329 (0.1240)  loss_bbox_enc_0: 0.1531 (0.1571)  loss_giou: 0.3095 (0.3186)  loss_giou_aux_0: 0.3183 (0.3286)  loss_giou_aux_1: 0.3079 (0.3212)  loss_giou_aux_2: 0.3097 (0.3193)  loss_giou_aux_3: 0.3092 (0.3188)  loss_giou_aux_4: 0.3178 (0.3187)  loss_giou_dn_0: 0.3421 (0.3449)  loss_giou_dn_1: 0.2910 (0.2882)  loss_giou_dn_2: 0.2836 (0.2811)  loss_giou_dn_3: 0.2811 (0.2795)  loss_giou_dn_4: 0.2809 (0.2789)  loss_giou_dn_5: 0.2810 (0.2790)  loss_giou_enc_0: 0.3619 (0.3748)  loss_vfl: 0.3731 (0.3814)  loss_vfl_aux_0: 0.4761 (0.4717)  loss_vfl_aux_1: 0.4065 (0.4129)  loss_vfl_aux_2: 0.3771 (0.3923)  loss_vfl_aux_3: 0.3744 (0.3840)  loss_vfl_aux_4: 0.3695 (0.3820)  loss_vfl_dn_0: 0.3594 (0.3588)  loss_vfl_dn_1: 0.3225 (0.3232)  loss_vfl_dn_2: 0.3184 (0.3186)  loss_vfl_dn_3: 0.3164 (0.3175)  loss_vfl_dn_4: 0.3150 (0.3170)  loss_vfl_dn_5: 0.3151 (0.3170)  loss_vfl_enc_0: 0.4862 (0.4931)  time: 0.5418  data: 0.0097  max mem: 5639
Epoch: [1]  [ 600/1519]  eta: 0:08:28  lr: 0.000004  lr2: 0.000040  loss: 10.5343 (10.6666)  loss_bbox: 0.1304 (0.1334)  loss_bbox_aux_0: 0.1319 (0.1382)  loss_bbox_aux_1: 0.1293 (0.1344)  loss_bbox_aux_2: 0.1312 (0.1339)  loss_bbox_aux_3: 0.1287 (0.1339)  loss_bbox_aux_4: 0.1304 (0.1333)  loss_bbox_dn_0: 0.1530 (0.1603)  loss_bbox_dn_1: 0.1186 (0.1312)  loss_bbox_dn_2: 0.1170 (0.1271)  loss_bbox_dn_3: 0.1169 (0.1247)  loss_bbox_dn_4: 0.1174 (0.1236)  loss_bbox_dn_5: 0.1174 (0.1236)  loss_bbox_enc_0: 0.1511 (0.1569)  loss_giou: 0.3135 (0.3184)  loss_giou_aux_0: 0.3263 (0.3281)  loss_giou_aux_1: 0.3154 (0.3209)  loss_giou_aux_2: 0.3167 (0.3191)  loss_giou_aux_3: 0.3164 (0.3185)  loss_giou_aux_4: 0.3142 (0.3185)  loss_giou_dn_0: 0.3389 (0.3445)  loss_giou_dn_1: 0.2833 (0.2880)  loss_giou_dn_2: 0.2764 (0.2810)  loss_giou_dn_3: 0.2741 (0.2793)  loss_giou_dn_4: 0.2738 (0.2788)  loss_giou_dn_5: 0.2738 (0.2788)  loss_giou_enc_0: 0.3660 (0.3743)  loss_vfl: 0.3712 (0.3807)  loss_vfl_aux_0: 0.4658 (0.4716)  loss_vfl_aux_1: 0.3954 (0.4120)  loss_vfl_aux_2: 0.3794 (0.3912)  loss_vfl_aux_3: 0.3758 (0.3832)  loss_vfl_aux_4: 0.3722 (0.3812)  loss_vfl_dn_0: 0.3577 (0.3587)  loss_vfl_dn_1: 0.3211 (0.3232)  loss_vfl_dn_2: 0.3179 (0.3186)  loss_vfl_dn_3: 0.3158 (0.3175)  loss_vfl_dn_4: 0.3152 (0.3170)  loss_vfl_dn_5: 0.3149 (0.3170)  loss_vfl_enc_0: 0.4951 (0.4921)  time: 0.4979  data: 0.0096  max mem: 5639
Epoch: [1]  [ 700/1519]  eta: 0:07:29  lr: 0.000004  lr2: 0.000040  loss: 10.3621 (10.6589)  loss_bbox: 0.1228 (0.1327)  loss_bbox_aux_0: 0.1354 (0.1376)  loss_bbox_aux_1: 0.1284 (0.1338)  loss_bbox_aux_2: 0.1256 (0.1333)  loss_bbox_aux_3: 0.1238 (0.1332)  loss_bbox_aux_4: 0.1228 (0.1326)  loss_bbox_dn_0: 0.1524 (0.1597)  loss_bbox_dn_1: 0.1278 (0.1308)  loss_bbox_dn_2: 0.1259 (0.1267)  loss_bbox_dn_3: 0.1155 (0.1243)  loss_bbox_dn_4: 0.1138 (0.1231)  loss_bbox_dn_5: 0.1138 (0.1231)  loss_bbox_enc_0: 0.1535 (0.1564)  loss_giou: 0.3096 (0.3183)  loss_giou_aux_0: 0.3211 (0.3280)  loss_giou_aux_1: 0.3106 (0.3208)  loss_giou_aux_2: 0.3097 (0.3189)  loss_giou_aux_3: 0.3075 (0.3184)  loss_giou_aux_4: 0.3096 (0.3183)  loss_giou_dn_0: 0.3380 (0.3443)  loss_giou_dn_1: 0.2802 (0.2879)  loss_giou_dn_2: 0.2720 (0.2808)  loss_giou_dn_3: 0.2697 (0.2792)  loss_giou_dn_4: 0.2685 (0.2786)  loss_giou_dn_5: 0.2685 (0.2787)  loss_giou_enc_0: 0.3708 (0.3744)  loss_vfl: 0.3729 (0.3810)  loss_vfl_aux_0: 0.4424 (0.4713)  loss_vfl_aux_1: 0.4061 (0.4126)  loss_vfl_aux_2: 0.3784 (0.3915)  loss_vfl_aux_3: 0.3757 (0.3838)  loss_vfl_aux_4: 0.3732 (0.3816)  loss_vfl_dn_0: 0.3553 (0.3585)  loss_vfl_dn_1: 0.3183 (0.3231)  loss_vfl_dn_2: 0.3126 (0.3185)  loss_vfl_dn_3: 0.3107 (0.3174)  loss_vfl_dn_4: 0.3094 (0.3169)  loss_vfl_dn_5: 0.3096 (0.3169)  loss_vfl_enc_0: 0.4755 (0.4921)  time: 0.4983  data: 0.0099  max mem: 5639
Epoch: [1]  [ 800/1519]  eta: 0:06:32  lr: 0.000004  lr2: 0.000040  loss: 10.5266 (10.6507)  loss_bbox: 0.1279 (0.1321)  loss_bbox_aux_0: 0.1375 (0.1370)  loss_bbox_aux_1: 0.1310 (0.1332)  loss_bbox_aux_2: 0.1264 (0.1327)  loss_bbox_aux_3: 0.1291 (0.1325)  loss_bbox_aux_4: 0.1279 (0.1320)  loss_bbox_dn_0: 0.1609 (0.1591)  loss_bbox_dn_1: 0.1324 (0.1305)  loss_bbox_dn_2: 0.1283 (0.1263)  loss_bbox_dn_3: 0.1236 (0.1239)  loss_bbox_dn_4: 0.1217 (0.1228)  loss_bbox_dn_5: 0.1217 (0.1228)  loss_bbox_enc_0: 0.1609 (0.1560)  loss_giou: 0.3031 (0.3180)  loss_giou_aux_0: 0.3210 (0.3276)  loss_giou_aux_1: 0.3015 (0.3205)  loss_giou_aux_2: 0.3046 (0.3186)  loss_giou_aux_3: 0.3043 (0.3180)  loss_giou_aux_4: 0.3048 (0.3180)  loss_giou_dn_0: 0.3421 (0.3439)  loss_giou_dn_1: 0.2815 (0.2877)  loss_giou_dn_2: 0.2763 (0.2807)  loss_giou_dn_3: 0.2735 (0.2790)  loss_giou_dn_4: 0.2733 (0.2785)  loss_giou_dn_5: 0.2734 (0.2785)  loss_giou_enc_0: 0.3597 (0.3742)  loss_vfl: 0.3843 (0.3814)  loss_vfl_aux_0: 0.4821 (0.4714)  loss_vfl_aux_1: 0.4067 (0.4130)  loss_vfl_aux_2: 0.3917 (0.3919)  loss_vfl_aux_3: 0.3855 (0.3844)  loss_vfl_aux_4: 0.3825 (0.3820)  loss_vfl_dn_0: 0.3521 (0.3583)  loss_vfl_dn_1: 0.3176 (0.3230)  loss_vfl_dn_2: 0.3119 (0.3184)  loss_vfl_dn_3: 0.3118 (0.3173)  loss_vfl_dn_4: 0.3113 (0.3168)  loss_vfl_dn_5: 0.3113 (0.3168)  loss_vfl_enc_0: 0.4762 (0.4916)  time: 0.4954  data: 0.0099  max mem: 5639
Epoch: [1]  [ 900/1519]  eta: 0:05:35  lr: 0.000004  lr2: 0.000040  loss: 10.5291 (10.6454)  loss_bbox: 0.1250 (0.1319)  loss_bbox_aux_0: 0.1302 (0.1368)  loss_bbox_aux_1: 0.1231 (0.1329)  loss_bbox_aux_2: 0.1221 (0.1325)  loss_bbox_aux_3: 0.1239 (0.1322)  loss_bbox_aux_4: 0.1251 (0.1319)  loss_bbox_dn_0: 0.1490 (0.1588)  loss_bbox_dn_1: 0.1253 (0.1303)  loss_bbox_dn_2: 0.1219 (0.1262)  loss_bbox_dn_3: 0.1181 (0.1238)  loss_bbox_dn_4: 0.1138 (0.1227)  loss_bbox_dn_5: 0.1138 (0.1227)  loss_bbox_enc_0: 0.1437 (0.1559)  loss_giou: 0.3109 (0.3179)  loss_giou_aux_0: 0.3194 (0.3274)  loss_giou_aux_1: 0.3122 (0.3203)  loss_giou_aux_2: 0.3104 (0.3185)  loss_giou_aux_3: 0.3086 (0.3178)  loss_giou_aux_4: 0.3113 (0.3179)  loss_giou_dn_0: 0.3420 (0.3438)  loss_giou_dn_1: 0.2840 (0.2877)  loss_giou_dn_2: 0.2767 (0.2806)  loss_giou_dn_3: 0.2759 (0.2790)  loss_giou_dn_4: 0.2755 (0.2785)  loss_giou_dn_5: 0.2756 (0.2785)  loss_giou_enc_0: 0.3614 (0.3741)  loss_vfl: 0.3699 (0.3813)  loss_vfl_aux_0: 0.4442 (0.4706)  loss_vfl_aux_1: 0.3905 (0.4131)  loss_vfl_aux_2: 0.3774 (0.3920)  loss_vfl_aux_3: 0.3753 (0.3845)  loss_vfl_aux_4: 0.3747 (0.3819)  loss_vfl_dn_0: 0.3576 (0.3582)  loss_vfl_dn_1: 0.3229 (0.3230)  loss_vfl_dn_2: 0.3185 (0.3184)  loss_vfl_dn_3: 0.3177 (0.3173)  loss_vfl_dn_4: 0.3168 (0.3168)  loss_vfl_dn_5: 0.3169 (0.3168)  loss_vfl_enc_0: 0.4741 (0.4906)  time: 0.4944  data: 0.0101  max mem: 5639
Epoch: [1]  [1000/1519]  eta: 0:04:41  lr: 0.000004  lr2: 0.000040  loss: 10.6812 (10.6358)  loss_bbox: 0.1239 (0.1318)  loss_bbox_aux_0: 0.1250 (0.1364)  loss_bbox_aux_1: 0.1247 (0.1327)  loss_bbox_aux_2: 0.1264 (0.1323)  loss_bbox_aux_3: 0.1272 (0.1320)  loss_bbox_aux_4: 0.1239 (0.1318)  loss_bbox_dn_0: 0.1648 (0.1587)  loss_bbox_dn_1: 0.1323 (0.1302)  loss_bbox_dn_2: 0.1273 (0.1261)  loss_bbox_dn_3: 0.1219 (0.1237)  loss_bbox_dn_4: 0.1191 (0.1226)  loss_bbox_dn_5: 0.1190 (0.1226)  loss_bbox_enc_0: 0.1466 (0.1558)  loss_giou: 0.3139 (0.3178)  loss_giou_aux_0: 0.3216 (0.3270)  loss_giou_aux_1: 0.3103 (0.3200)  loss_giou_aux_2: 0.3142 (0.3183)  loss_giou_aux_3: 0.3160 (0.3177)  loss_giou_aux_4: 0.3139 (0.3177)  loss_giou_dn_0: 0.3530 (0.3435)  loss_giou_dn_1: 0.2862 (0.2874)  loss_giou_dn_2: 0.2808 (0.2804)  loss_giou_dn_3: 0.2786 (0.2788)  loss_giou_dn_4: 0.2784 (0.2782)  loss_giou_dn_5: 0.2785 (0.2783)  loss_giou_enc_0: 0.3815 (0.3738)  loss_vfl: 0.3813 (0.3808)  loss_vfl_aux_0: 0.4792 (0.4702)  loss_vfl_aux_1: 0.4208 (0.4126)  loss_vfl_aux_2: 0.3936 (0.3914)  loss_vfl_aux_3: 0.3899 (0.3840)  loss_vfl_aux_4: 0.3844 (0.3814)  loss_vfl_dn_0: 0.3564 (0.3580)  loss_vfl_dn_1: 0.3225 (0.3229)  loss_vfl_dn_2: 0.3169 (0.3183)  loss_vfl_dn_3: 0.3151 (0.3172)  loss_vfl_dn_4: 0.3147 (0.3167)  loss_vfl_dn_5: 0.3142 (0.3167)  loss_vfl_enc_0: 0.4919 (0.4901)  time: 0.5832  data: 0.0096  max mem: 5639
Epoch: [1]  [1100/1519]  eta: 0:03:46  lr: 0.000004  lr2: 0.000040  loss: 10.6860 (10.6432)  loss_bbox: 0.1368 (0.1320)  loss_bbox_aux_0: 0.1357 (0.1365)  loss_bbox_aux_1: 0.1312 (0.1328)  loss_bbox_aux_2: 0.1342 (0.1324)  loss_bbox_aux_3: 0.1354 (0.1321)  loss_bbox_aux_4: 0.1368 (0.1320)  loss_bbox_dn_0: 0.1589 (0.1588)  loss_bbox_dn_1: 0.1291 (0.1303)  loss_bbox_dn_2: 0.1263 (0.1262)  loss_bbox_dn_3: 0.1227 (0.1238)  loss_bbox_dn_4: 0.1222 (0.1227)  loss_bbox_dn_5: 0.1222 (0.1227)  loss_bbox_enc_0: 0.1567 (0.1560)  loss_giou: 0.3152 (0.3180)  loss_giou_aux_0: 0.3287 (0.3271)  loss_giou_aux_1: 0.3197 (0.3202)  loss_giou_aux_2: 0.3180 (0.3185)  loss_giou_aux_3: 0.3162 (0.3179)  loss_giou_aux_4: 0.3152 (0.3180)  loss_giou_dn_0: 0.3438 (0.3436)  loss_giou_dn_1: 0.2825 (0.2876)  loss_giou_dn_2: 0.2757 (0.2806)  loss_giou_dn_3: 0.2731 (0.2789)  loss_giou_dn_4: 0.2723 (0.2784)  loss_giou_dn_5: 0.2723 (0.2785)  loss_giou_enc_0: 0.3770 (0.3738)  loss_vfl: 0.3735 (0.3809)  loss_vfl_aux_0: 0.4722 (0.4708)  loss_vfl_aux_1: 0.4224 (0.4132)  loss_vfl_aux_2: 0.3959 (0.3918)  loss_vfl_aux_3: 0.3746 (0.3842)  loss_vfl_aux_4: 0.3729 (0.3815)  loss_vfl_dn_0: 0.3600 (0.3581)  loss_vfl_dn_1: 0.3228 (0.3229)  loss_vfl_dn_2: 0.3167 (0.3184)  loss_vfl_dn_3: 0.3160 (0.3173)  loss_vfl_dn_4: 0.3159 (0.3168)  loss_vfl_dn_5: 0.3162 (0.3168)  loss_vfl_enc_0: 0.4847 (0.4909)  time: 0.5786  data: 0.0100  max mem: 5639
Epoch: [1]  [1200/1519]  eta: 0:02:52  lr: 0.000004  lr2: 0.000040  loss: 10.7051 (10.6414)  loss_bbox: 0.1269 (0.1322)  loss_bbox_aux_0: 0.1327 (0.1367)  loss_bbox_aux_1: 0.1270 (0.1329)  loss_bbox_aux_2: 0.1259 (0.1325)  loss_bbox_aux_3: 0.1269 (0.1323)  loss_bbox_aux_4: 0.1269 (0.1322)  loss_bbox_dn_0: 0.1544 (0.1589)  loss_bbox_dn_1: 0.1183 (0.1304)  loss_bbox_dn_2: 0.1144 (0.1262)  loss_bbox_dn_3: 0.1118 (0.1238)  loss_bbox_dn_4: 0.1098 (0.1227)  loss_bbox_dn_5: 0.1098 (0.1227)  loss_bbox_enc_0: 0.1500 (0.1562)  loss_giou: 0.3099 (0.3181)  loss_giou_aux_0: 0.3222 (0.3272)  loss_giou_aux_1: 0.3182 (0.3201)  loss_giou_aux_2: 0.3161 (0.3184)  loss_giou_aux_3: 0.3158 (0.3178)  loss_giou_aux_4: 0.3099 (0.3181)  loss_giou_dn_0: 0.3392 (0.3435)  loss_giou_dn_1: 0.2849 (0.2875)  loss_giou_dn_2: 0.2775 (0.2805)  loss_giou_dn_3: 0.2763 (0.2788)  loss_giou_dn_4: 0.2756 (0.2783)  loss_giou_dn_5: 0.2756 (0.2784)  loss_giou_enc_0: 0.3737 (0.3738)  loss_vfl: 0.3771 (0.3804)  loss_vfl_aux_0: 0.4484 (0.4704)  loss_vfl_aux_1: 0.4089 (0.4132)  loss_vfl_aux_2: 0.3942 (0.3917)  loss_vfl_aux_3: 0.3793 (0.3840)  loss_vfl_aux_4: 0.3755 (0.3810)  loss_vfl_dn_0: 0.3590 (0.3581)  loss_vfl_dn_1: 0.3222 (0.3229)  loss_vfl_dn_2: 0.3151 (0.3184)  loss_vfl_dn_3: 0.3137 (0.3172)  loss_vfl_dn_4: 0.3137 (0.3168)  loss_vfl_dn_5: 0.3136 (0.3167)  loss_vfl_enc_0: 0.4981 (0.4905)  time: 0.4988  data: 0.0102  max mem: 5639
Epoch: [1]  [1300/1519]  eta: 0:01:58  lr: 0.000004  lr2: 0.000040  loss: 10.5233 (10.6283)  loss_bbox: 0.1317 (0.1319)  loss_bbox_aux_0: 0.1384 (0.1365)  loss_bbox_aux_1: 0.1360 (0.1326)  loss_bbox_aux_2: 0.1335 (0.1321)  loss_bbox_aux_3: 0.1307 (0.1319)  loss_bbox_aux_4: 0.1317 (0.1318)  loss_bbox_dn_0: 0.1580 (0.1586)  loss_bbox_dn_1: 0.1357 (0.1301)  loss_bbox_dn_2: 0.1326 (0.1260)  loss_bbox_dn_3: 0.1284 (0.1235)  loss_bbox_dn_4: 0.1257 (0.1224)  loss_bbox_dn_5: 0.1257 (0.1225)  loss_bbox_enc_0: 0.1524 (0.1560)  loss_giou: 0.3144 (0.3177)  loss_giou_aux_0: 0.3213 (0.3269)  loss_giou_aux_1: 0.3171 (0.3198)  loss_giou_aux_2: 0.3144 (0.3180)  loss_giou_aux_3: 0.3141 (0.3174)  loss_giou_aux_4: 0.3145 (0.3177)  loss_giou_dn_0: 0.3375 (0.3432)  loss_giou_dn_1: 0.2862 (0.2872)  loss_giou_dn_2: 0.2784 (0.2802)  loss_giou_dn_3: 0.2762 (0.2785)  loss_giou_dn_4: 0.2760 (0.2780)  loss_giou_dn_5: 0.2761 (0.2780)  loss_giou_enc_0: 0.3695 (0.3736)  loss_vfl: 0.3734 (0.3798)  loss_vfl_aux_0: 0.4625 (0.4697)  loss_vfl_aux_1: 0.4004 (0.4123)  loss_vfl_aux_2: 0.3810 (0.3911)  loss_vfl_aux_3: 0.3812 (0.3835)  loss_vfl_aux_4: 0.3737 (0.3805)  loss_vfl_dn_0: 0.3568 (0.3579)  loss_vfl_dn_1: 0.3205 (0.3227)  loss_vfl_dn_2: 0.3173 (0.3182)  loss_vfl_dn_3: 0.3161 (0.3171)  loss_vfl_dn_4: 0.3157 (0.3166)  loss_vfl_dn_5: 0.3158 (0.3166)  loss_vfl_enc_0: 0.4863 (0.4900)  time: 0.5418  data: 0.0100  max mem: 5639
Epoch: [1]  [1400/1519]  eta: 0:01:03  lr: 0.000004  lr2: 0.000040  loss: 10.6433 (10.6217)  loss_bbox: 0.1261 (0.1318)  loss_bbox_aux_0: 0.1354 (0.1363)  loss_bbox_aux_1: 0.1291 (0.1325)  loss_bbox_aux_2: 0.1271 (0.1320)  loss_bbox_aux_3: 0.1261 (0.1318)  loss_bbox_aux_4: 0.1261 (0.1317)  loss_bbox_dn_0: 0.1465 (0.1582)  loss_bbox_dn_1: 0.1206 (0.1299)  loss_bbox_dn_2: 0.1192 (0.1258)  loss_bbox_dn_3: 0.1169 (0.1234)  loss_bbox_dn_4: 0.1167 (0.1223)  loss_bbox_dn_5: 0.1167 (0.1223)  loss_bbox_enc_0: 0.1519 (0.1558)  loss_giou: 0.3142 (0.3174)  loss_giou_aux_0: 0.3210 (0.3266)  loss_giou_aux_1: 0.3180 (0.3195)  loss_giou_aux_2: 0.3138 (0.3177)  loss_giou_aux_3: 0.3141 (0.3172)  loss_giou_aux_4: 0.3141 (0.3174)  loss_giou_dn_0: 0.3346 (0.3428)  loss_giou_dn_1: 0.2843 (0.2870)  loss_giou_dn_2: 0.2803 (0.2800)  loss_giou_dn_3: 0.2794 (0.2784)  loss_giou_dn_4: 0.2795 (0.2778)  loss_giou_dn_5: 0.2795 (0.2779)  loss_giou_enc_0: 0.3659 (0.3734)  loss_vfl: 0.3751 (0.3797)  loss_vfl_aux_0: 0.4514 (0.4693)  loss_vfl_aux_1: 0.3989 (0.4122)  loss_vfl_aux_2: 0.3852 (0.3912)  loss_vfl_aux_3: 0.3911 (0.3836)  loss_vfl_aux_4: 0.3776 (0.3804)  loss_vfl_dn_0: 0.3560 (0.3578)  loss_vfl_dn_1: 0.3243 (0.3227)  loss_vfl_dn_2: 0.3209 (0.3182)  loss_vfl_dn_3: 0.3206 (0.3170)  loss_vfl_dn_4: 0.3204 (0.3166)  loss_vfl_dn_5: 0.3203 (0.3165)  loss_vfl_enc_0: 0.4731 (0.4894)  time: 0.5016  data: 0.0099  max mem: 5639
Epoch: [1]  [1500/1519]  eta: 0:00:10  lr: 0.000004  lr2: 0.000040  loss: 10.2107 (10.6205)  loss_bbox: 0.1265 (0.1318)  loss_bbox_aux_0: 0.1414 (0.1363)  loss_bbox_aux_1: 0.1347 (0.1325)  loss_bbox_aux_2: 0.1286 (0.1320)  loss_bbox_aux_3: 0.1273 (0.1318)  loss_bbox_aux_4: 0.1266 (0.1317)  loss_bbox_dn_0: 0.1449 (0.1580)  loss_bbox_dn_1: 0.1201 (0.1297)  loss_bbox_dn_2: 0.1169 (0.1256)  loss_bbox_dn_3: 0.1177 (0.1232)  loss_bbox_dn_4: 0.1174 (0.1221)  loss_bbox_dn_5: 0.1174 (0.1222)  loss_bbox_enc_0: 0.1498 (0.1557)  loss_giou: 0.3114 (0.3176)  loss_giou_aux_0: 0.3220 (0.3267)  loss_giou_aux_1: 0.3142 (0.3197)  loss_giou_aux_2: 0.3145 (0.3179)  loss_giou_aux_3: 0.3105 (0.3173)  loss_giou_aux_4: 0.3114 (0.3176)  loss_giou_dn_0: 0.3391 (0.3428)  loss_giou_dn_1: 0.2820 (0.2871)  loss_giou_dn_2: 0.2741 (0.2801)  loss_giou_dn_3: 0.2702 (0.2784)  loss_giou_dn_4: 0.2684 (0.2779)  loss_giou_dn_5: 0.2684 (0.2780)  loss_giou_enc_0: 0.3685 (0.3734)  loss_vfl: 0.3664 (0.3796)  loss_vfl_aux_0: 0.4480 (0.4692)  loss_vfl_aux_1: 0.3944 (0.4119)  loss_vfl_aux_2: 0.3751 (0.3911)  loss_vfl_aux_3: 0.3681 (0.3836)  loss_vfl_aux_4: 0.3684 (0.3803)  loss_vfl_dn_0: 0.3569 (0.3577)  loss_vfl_dn_1: 0.3223 (0.3227)  loss_vfl_dn_2: 0.3173 (0.3182)  loss_vfl_dn_3: 0.3158 (0.3170)  loss_vfl_dn_4: 0.3152 (0.3166)  loss_vfl_dn_5: 0.3151 (0.3166)  loss_vfl_enc_0: 0.4720 (0.4890)  time: 0.4575  data: 0.0090  max mem: 5639
Epoch: [1]  [1518/1519]  eta: 0:00:00  lr: 0.000004  lr2: 0.000040  loss: 10.3815 (10.6195)  loss_bbox: 0.1224 (0.1317)  loss_bbox_aux_0: 0.1246 (0.1362)  loss_bbox_aux_1: 0.1245 (0.1324)  loss_bbox_aux_2: 0.1231 (0.1319)  loss_bbox_aux_3: 0.1222 (0.1317)  loss_bbox_aux_4: 0.1224 (0.1317)  loss_bbox_dn_0: 0.1381 (0.1579)  loss_bbox_dn_1: 0.1145 (0.1296)  loss_bbox_dn_2: 0.1097 (0.1255)  loss_bbox_dn_3: 0.1080 (0.1231)  loss_bbox_dn_4: 0.1075 (0.1220)  loss_bbox_dn_5: 0.1075 (0.1220)  loss_bbox_enc_0: 0.1571 (0.1557)  loss_giou: 0.3255 (0.3177)  loss_giou_aux_0: 0.3325 (0.3267)  loss_giou_aux_1: 0.3278 (0.3197)  loss_giou_aux_2: 0.3255 (0.3179)  loss_giou_aux_3: 0.3249 (0.3174)  loss_giou_aux_4: 0.3255 (0.3176)  loss_giou_dn_0: 0.3443 (0.3429)  loss_giou_dn_1: 0.2865 (0.2871)  loss_giou_dn_2: 0.2810 (0.2801)  loss_giou_dn_3: 0.2804 (0.2785)  loss_giou_dn_4: 0.2803 (0.2780)  loss_giou_dn_5: 0.2803 (0.2780)  loss_giou_enc_0: 0.3817 (0.3735)  loss_vfl: 0.3732 (0.3795)  loss_vfl_aux_0: 0.4704 (0.4691)  loss_vfl_aux_1: 0.4130 (0.4119)  loss_vfl_aux_2: 0.3840 (0.3910)  loss_vfl_aux_3: 0.3725 (0.3834)  loss_vfl_aux_4: 0.3732 (0.3802)  loss_vfl_dn_0: 0.3621 (0.3577)  loss_vfl_dn_1: 0.3258 (0.3227)  loss_vfl_dn_2: 0.3228 (0.3182)  loss_vfl_dn_3: 0.3218 (0.3171)  loss_vfl_dn_4: 0.3215 (0.3166)  loss_vfl_dn_5: 0.3214 (0.3166)  loss_vfl_enc_0: 0.4834 (0.4890)  time: 0.4399  data: 0.0084  max mem: 5639
Epoch: [1] Total time: 0:13:32 (0.5352 s / it)
Averaged stats: lr: 0.000004  lr2: 0.000040  loss: 10.3815 (10.6195)  loss_bbox: 0.1224 (0.1317)  loss_bbox_aux_0: 0.1246 (0.1362)  loss_bbox_aux_1: 0.1245 (0.1324)  loss_bbox_aux_2: 0.1231 (0.1319)  loss_bbox_aux_3: 0.1222 (0.1317)  loss_bbox_aux_4: 0.1224 (0.1317)  loss_bbox_dn_0: 0.1381 (0.1579)  loss_bbox_dn_1: 0.1145 (0.1296)  loss_bbox_dn_2: 0.1097 (0.1255)  loss_bbox_dn_3: 0.1080 (0.1231)  loss_bbox_dn_4: 0.1075 (0.1220)  loss_bbox_dn_5: 0.1075 (0.1220)  loss_bbox_enc_0: 0.1571 (0.1557)  loss_giou: 0.3255 (0.3177)  loss_giou_aux_0: 0.3325 (0.3267)  loss_giou_aux_1: 0.3278 (0.3197)  loss_giou_aux_2: 0.3255 (0.3179)  loss_giou_aux_3: 0.3249 (0.3174)  loss_giou_aux_4: 0.3255 (0.3176)  loss_giou_dn_0: 0.3443 (0.3429)  loss_giou_dn_1: 0.2865 (0.2871)  loss_giou_dn_2: 0.2810 (0.2801)  loss_giou_dn_3: 0.2804 (0.2785)  loss_giou_dn_4: 0.2803 (0.2780)  loss_giou_dn_5: 0.2803 (0.2780)  loss_giou_enc_0: 0.3817 (0.3735)  loss_vfl: 0.3732 (0.3795)  loss_vfl_aux_0: 0.4704 (0.4691)  loss_vfl_aux_1: 0.4130 (0.4119)  loss_vfl_aux_2: 0.3840 (0.3910)  loss_vfl_aux_3: 0.3725 (0.3834)  loss_vfl_aux_4: 0.3732 (0.3802)  loss_vfl_dn_0: 0.3621 (0.3577)  loss_vfl_dn_1: 0.3258 (0.3227)  loss_vfl_dn_2: 0.3228 (0.3182)  loss_vfl_dn_3: 0.3218 (0.3171)  loss_vfl_dn_4: 0.3215 (0.3166)  loss_vfl_dn_5: 0.3214 (0.3166)  loss_vfl_enc_0: 0.4834 (0.4890)
Test:  [  0/165]  eta: 0:08:18    time: 3.0241  data: 2.7710  max mem: 5639
Test:  [ 10/165]  eta: 0:01:23    time: 0.5398  data: 0.2826  max mem: 5639
Test:  [ 20/165]  eta: 0:00:57    time: 0.2629  data: 0.0322  max mem: 5639
Test:  [ 30/165]  eta: 0:00:47    time: 0.2493  data: 0.0230  max mem: 5639
Test:  [ 40/165]  eta: 0:00:40    time: 0.2509  data: 0.0242  max mem: 5639
Test:  [ 50/165]  eta: 0:00:35    time: 0.2369  data: 0.0318  max mem: 5639
Test:  [ 60/165]  eta: 0:00:31    time: 0.2528  data: 0.0251  max mem: 5639
Test:  [ 70/165]  eta: 0:00:27    time: 0.2481  data: 0.0235  max mem: 5639
Test:  [ 80/165]  eta: 0:00:24    time: 0.2465  data: 0.0223  max mem: 5639
Test:  [ 90/165]  eta: 0:00:21    time: 0.2523  data: 0.0262  max mem: 5639
Test:  [100/165]  eta: 0:00:18    time: 0.2355  data: 0.0315  max mem: 5639
Test:  [110/165]  eta: 0:00:15    time: 0.2556  data: 0.0230  max mem: 5639
Test:  [120/165]  eta: 0:00:12    time: 0.2594  data: 0.0257  max mem: 5639
Test:  [130/165]  eta: 0:00:09    time: 0.2343  data: 0.0324  max mem: 5639
Test:  [140/165]  eta: 0:00:06    time: 0.2416  data: 0.0242  max mem: 5639
Test:  [150/165]  eta: 0:00:03    time: 0.2340  data: 0.0197  max mem: 5639
Test:  [160/165]  eta: 0:00:01    time: 0.2365  data: 0.0209  max mem: 5639
Test:  [164/165]  eta: 0:00:00    time: 0.2304  data: 0.0221  max mem: 5639
Test: Total time: 0:00:43 (0.2642 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=27.48s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.484
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
best_stat: {'epoch': 0, 'coco_eval_bbox': 0.4708596759809729}
Epoch: [2]  [   0/1519]  eta: 4:03:09  lr: 0.000004  lr2: 0.000040  loss: 10.8209 (10.8209)  loss_bbox: 0.1253 (0.1253)  loss_bbox_aux_0: 0.1294 (0.1294)  loss_bbox_aux_1: 0.1290 (0.1290)  loss_bbox_aux_2: 0.1255 (0.1255)  loss_bbox_aux_3: 0.1263 (0.1263)  loss_bbox_aux_4: 0.1253 (0.1253)  loss_bbox_dn_0: 0.1630 (0.1630)  loss_bbox_dn_1: 0.1399 (0.1399)  loss_bbox_dn_2: 0.1371 (0.1371)  loss_bbox_dn_3: 0.1349 (0.1349)  loss_bbox_dn_4: 0.1324 (0.1324)  loss_bbox_dn_5: 0.1324 (0.1324)  loss_bbox_enc_0: 0.1556 (0.1556)  loss_giou: 0.3238 (0.3238)  loss_giou_aux_0: 0.3283 (0.3283)  loss_giou_aux_1: 0.3255 (0.3255)  loss_giou_aux_2: 0.3239 (0.3239)  loss_giou_aux_3: 0.3250 (0.3250)  loss_giou_aux_4: 0.3238 (0.3238)  loss_giou_dn_0: 0.3510 (0.3510)  loss_giou_dn_1: 0.2892 (0.2892)  loss_giou_dn_2: 0.2834 (0.2834)  loss_giou_dn_3: 0.2825 (0.2825)  loss_giou_dn_4: 0.2813 (0.2813)  loss_giou_dn_5: 0.2813 (0.2813)  loss_giou_enc_0: 0.3597 (0.3597)  loss_vfl: 0.3971 (0.3971)  loss_vfl_aux_0: 0.4859 (0.4859)  loss_vfl_aux_1: 0.4180 (0.4180)  loss_vfl_aux_2: 0.4115 (0.4115)  loss_vfl_aux_3: 0.3962 (0.3962)  loss_vfl_aux_4: 0.3975 (0.3975)  loss_vfl_dn_0: 0.3649 (0.3649)  loss_vfl_dn_1: 0.3301 (0.3301)  loss_vfl_dn_2: 0.3267 (0.3267)  loss_vfl_dn_3: 0.3255 (0.3255)  loss_vfl_dn_4: 0.3250 (0.3250)  loss_vfl_dn_5: 0.3248 (0.3248)  loss_vfl_enc_0: 0.4826 (0.4826)  time: 9.6048  data: 4.9667  max mem: 5639
Epoch: [2]  [ 100/1519]  eta: 0:15:32  lr: 0.000004  lr2: 0.000040  loss: 10.5179 (10.4698)  loss_bbox: 0.1321 (0.1322)  loss_bbox_aux_0: 0.1351 (0.1341)  loss_bbox_aux_1: 0.1343 (0.1314)  loss_bbox_aux_2: 0.1339 (0.1308)  loss_bbox_aux_3: 0.1342 (0.1313)  loss_bbox_aux_4: 0.1344 (0.1323)  loss_bbox_dn_0: 0.1516 (0.1531)  loss_bbox_dn_1: 0.1339 (0.1265)  loss_bbox_dn_2: 0.1289 (0.1228)  loss_bbox_dn_3: 0.1264 (0.1205)  loss_bbox_dn_4: 0.1260 (0.1195)  loss_bbox_dn_5: 0.1260 (0.1195)  loss_bbox_enc_0: 0.1562 (0.1540)  loss_giou: 0.3091 (0.3152)  loss_giou_aux_0: 0.3144 (0.3225)  loss_giou_aux_1: 0.3106 (0.3163)  loss_giou_aux_2: 0.3124 (0.3148)  loss_giou_aux_3: 0.3120 (0.3141)  loss_giou_aux_4: 0.3091 (0.3152)  loss_giou_dn_0: 0.3330 (0.3373)  loss_giou_dn_1: 0.2849 (0.2830)  loss_giou_dn_2: 0.2770 (0.2764)  loss_giou_dn_3: 0.2747 (0.2749)  loss_giou_dn_4: 0.2749 (0.2744)  loss_giou_dn_5: 0.2749 (0.2744)  loss_giou_enc_0: 0.3583 (0.3697)  loss_vfl: 0.3722 (0.3693)  loss_vfl_aux_0: 0.4648 (0.4596)  loss_vfl_aux_1: 0.4005 (0.4012)  loss_vfl_aux_2: 0.3831 (0.3822)  loss_vfl_aux_3: 0.3718 (0.3754)  loss_vfl_aux_4: 0.3743 (0.3694)  loss_vfl_dn_0: 0.3539 (0.3552)  loss_vfl_dn_1: 0.3205 (0.3206)  loss_vfl_dn_2: 0.3156 (0.3162)  loss_vfl_dn_3: 0.3132 (0.3152)  loss_vfl_dn_4: 0.3133 (0.3147)  loss_vfl_dn_5: 0.3132 (0.3146)  loss_vfl_enc_0: 0.4876 (0.4801)  time: 0.5091  data: 0.0102  max mem: 5639
Epoch: [2]  [ 200/1519]  eta: 0:12:58  lr: 0.000004  lr2: 0.000040  loss: 10.4837 (10.4654)  loss_bbox: 0.1236 (0.1298)  loss_bbox_aux_0: 0.1283 (0.1330)  loss_bbox_aux_1: 0.1249 (0.1298)  loss_bbox_aux_2: 0.1256 (0.1292)  loss_bbox_aux_3: 0.1237 (0.1295)  loss_bbox_aux_4: 0.1236 (0.1300)  loss_bbox_dn_0: 0.1504 (0.1537)  loss_bbox_dn_1: 0.1236 (0.1266)  loss_bbox_dn_2: 0.1186 (0.1229)  loss_bbox_dn_3: 0.1160 (0.1205)  loss_bbox_dn_4: 0.1142 (0.1194)  loss_bbox_dn_5: 0.1142 (0.1195)  loss_bbox_enc_0: 0.1523 (0.1534)  loss_giou: 0.3173 (0.3144)  loss_giou_aux_0: 0.3244 (0.3223)  loss_giou_aux_1: 0.3161 (0.3164)  loss_giou_aux_2: 0.3143 (0.3146)  loss_giou_aux_3: 0.3177 (0.3136)  loss_giou_aux_4: 0.3172 (0.3143)  loss_giou_dn_0: 0.3401 (0.3374)  loss_giou_dn_1: 0.2875 (0.2829)  loss_giou_dn_2: 0.2806 (0.2764)  loss_giou_dn_3: 0.2773 (0.2748)  loss_giou_dn_4: 0.2763 (0.2743)  loss_giou_dn_5: 0.2763 (0.2743)  loss_giou_enc_0: 0.3777 (0.3690)  loss_vfl: 0.3743 (0.3727)  loss_vfl_aux_0: 0.4604 (0.4593)  loss_vfl_aux_1: 0.3976 (0.4018)  loss_vfl_aux_2: 0.3842 (0.3841)  loss_vfl_aux_3: 0.3800 (0.3773)  loss_vfl_aux_4: 0.3743 (0.3727)  loss_vfl_dn_0: 0.3569 (0.3550)  loss_vfl_dn_1: 0.3241 (0.3207)  loss_vfl_dn_2: 0.3194 (0.3165)  loss_vfl_dn_3: 0.3187 (0.3155)  loss_vfl_dn_4: 0.3181 (0.3150)  loss_vfl_dn_5: 0.3186 (0.3149)  loss_vfl_enc_0: 0.4807 (0.4778)  time: 0.4966  data: 0.0104  max mem: 5639
Epoch: [2]  [ 300/1519]  eta: 0:11:45  lr: 0.000004  lr2: 0.000040  loss: 10.2120 (10.4979)  loss_bbox: 0.1210 (0.1295)  loss_bbox_aux_0: 0.1313 (0.1332)  loss_bbox_aux_1: 0.1271 (0.1301)  loss_bbox_aux_2: 0.1214 (0.1292)  loss_bbox_aux_3: 0.1206 (0.1292)  loss_bbox_aux_4: 0.1210 (0.1297)  loss_bbox_dn_0: 0.1424 (0.1542)  loss_bbox_dn_1: 0.1177 (0.1271)  loss_bbox_dn_2: 0.1133 (0.1234)  loss_bbox_dn_3: 0.1108 (0.1209)  loss_bbox_dn_4: 0.1099 (0.1199)  loss_bbox_dn_5: 0.1099 (0.1199)  loss_bbox_enc_0: 0.1529 (0.1531)  loss_giou: 0.3129 (0.3152)  loss_giou_aux_0: 0.3288 (0.3232)  loss_giou_aux_1: 0.3193 (0.3175)  loss_giou_aux_2: 0.3161 (0.3154)  loss_giou_aux_3: 0.3141 (0.3146)  loss_giou_aux_4: 0.3141 (0.3151)  loss_giou_dn_0: 0.3265 (0.3385)  loss_giou_dn_1: 0.2811 (0.2840)  loss_giou_dn_2: 0.2742 (0.2773)  loss_giou_dn_3: 0.2718 (0.2757)  loss_giou_dn_4: 0.2710 (0.2752)  loss_giou_dn_5: 0.2711 (0.2752)  loss_giou_enc_0: 0.3733 (0.3691)  loss_vfl: 0.3668 (0.3750)  loss_vfl_aux_0: 0.4440 (0.4616)  loss_vfl_aux_1: 0.4021 (0.4042)  loss_vfl_aux_2: 0.3847 (0.3863)  loss_vfl_aux_3: 0.3729 (0.3793)  loss_vfl_aux_4: 0.3681 (0.3750)  loss_vfl_dn_0: 0.3554 (0.3557)  loss_vfl_dn_1: 0.3241 (0.3214)  loss_vfl_dn_2: 0.3200 (0.3172)  loss_vfl_dn_3: 0.3188 (0.3161)  loss_vfl_dn_4: 0.3181 (0.3156)  loss_vfl_dn_5: 0.3184 (0.3156)  loss_vfl_enc_0: 0.4622 (0.4794)  time: 0.5060  data: 0.0099  max mem: 5639
Epoch: [2]  [ 400/1519]  eta: 0:10:31  lr: 0.000004  lr2: 0.000040  loss: 10.7466 (10.4819)  loss_bbox: 0.1285 (0.1287)  loss_bbox_aux_0: 0.1346 (0.1328)  loss_bbox_aux_1: 0.1258 (0.1296)  loss_bbox_aux_2: 0.1263 (0.1285)  loss_bbox_aux_3: 0.1257 (0.1283)  loss_bbox_aux_4: 0.1257 (0.1288)  loss_bbox_dn_0: 0.1487 (0.1533)  loss_bbox_dn_1: 0.1251 (0.1262)  loss_bbox_dn_2: 0.1215 (0.1224)  loss_bbox_dn_3: 0.1200 (0.1200)  loss_bbox_dn_4: 0.1199 (0.1190)  loss_bbox_dn_5: 0.1199 (0.1190)  loss_bbox_enc_0: 0.1489 (0.1527)  loss_giou: 0.3166 (0.3145)  loss_giou_aux_0: 0.3297 (0.3227)  loss_giou_aux_1: 0.3207 (0.3168)  loss_giou_aux_2: 0.3182 (0.3149)  loss_giou_aux_3: 0.3167 (0.3139)  loss_giou_aux_4: 0.3164 (0.3145)  loss_giou_dn_0: 0.3475 (0.3380)  loss_giou_dn_1: 0.2887 (0.2833)  loss_giou_dn_2: 0.2813 (0.2767)  loss_giou_dn_3: 0.2802 (0.2752)  loss_giou_dn_4: 0.2796 (0.2746)  loss_giou_dn_5: 0.2796 (0.2747)  loss_giou_enc_0: 0.3732 (0.3693)  loss_vfl: 0.3825 (0.3750)  loss_vfl_aux_0: 0.4626 (0.4621)  loss_vfl_aux_1: 0.3994 (0.4052)  loss_vfl_aux_2: 0.3864 (0.3867)  loss_vfl_aux_3: 0.3829 (0.3796)  loss_vfl_aux_4: 0.3838 (0.3752)  loss_vfl_dn_0: 0.3587 (0.3555)  loss_vfl_dn_1: 0.3240 (0.3212)  loss_vfl_dn_2: 0.3196 (0.3170)  loss_vfl_dn_3: 0.3177 (0.3159)  loss_vfl_dn_4: 0.3173 (0.3154)  loss_vfl_dn_5: 0.3173 (0.3154)  loss_vfl_enc_0: 0.4666 (0.4797)  time: 0.5682  data: 0.0103  max mem: 5639
Epoch: [2]  [ 500/1519]  eta: 0:09:32  lr: 0.000004  lr2: 0.000040  loss: 10.3288 (10.4772)  loss_bbox: 0.1202 (0.1288)  loss_bbox_aux_0: 0.1234 (0.1330)  loss_bbox_aux_1: 0.1232 (0.1296)  loss_bbox_aux_2: 0.1195 (0.1285)  loss_bbox_aux_3: 0.1193 (0.1284)  loss_bbox_aux_4: 0.1202 (0.1289)  loss_bbox_dn_0: 0.1391 (0.1538)  loss_bbox_dn_1: 0.1120 (0.1267)  loss_bbox_dn_2: 0.1074 (0.1229)  loss_bbox_dn_3: 0.1059 (0.1204)  loss_bbox_dn_4: 0.1039 (0.1194)  loss_bbox_dn_5: 0.1039 (0.1194)  loss_bbox_enc_0: 0.1414 (0.1529)  loss_giou: 0.3112 (0.3136)  loss_giou_aux_0: 0.3164 (0.3220)  loss_giou_aux_1: 0.3142 (0.3159)  loss_giou_aux_2: 0.3092 (0.3139)  loss_giou_aux_3: 0.3131 (0.3131)  loss_giou_aux_4: 0.3125 (0.3134)  loss_giou_dn_0: 0.3358 (0.3377)  loss_giou_dn_1: 0.2770 (0.2833)  loss_giou_dn_2: 0.2709 (0.2766)  loss_giou_dn_3: 0.2683 (0.2750)  loss_giou_dn_4: 0.2680 (0.2745)  loss_giou_dn_5: 0.2680 (0.2745)  loss_giou_enc_0: 0.3769 (0.3689)  loss_vfl: 0.3619 (0.3750)  loss_vfl_aux_0: 0.4449 (0.4615)  loss_vfl_aux_1: 0.3895 (0.4051)  loss_vfl_aux_2: 0.3798 (0.3864)  loss_vfl_aux_3: 0.3640 (0.3793)  loss_vfl_aux_4: 0.3630 (0.3753)  loss_vfl_dn_0: 0.3556 (0.3553)  loss_vfl_dn_1: 0.3169 (0.3211)  loss_vfl_dn_2: 0.3146 (0.3168)  loss_vfl_dn_3: 0.3137 (0.3157)  loss_vfl_dn_4: 0.3133 (0.3152)  loss_vfl_dn_5: 0.3133 (0.3152)  loss_vfl_enc_0: 0.4678 (0.4802)  time: 0.4989  data: 0.0097  max mem: 5639
Epoch: [2]  [ 600/1519]  eta: 0:08:33  lr: 0.000004  lr2: 0.000040  loss: 10.4715 (10.4777)  loss_bbox: 0.1247 (0.1287)  loss_bbox_aux_0: 0.1279 (0.1329)  loss_bbox_aux_1: 0.1256 (0.1296)  loss_bbox_aux_2: 0.1262 (0.1285)  loss_bbox_aux_3: 0.1237 (0.1283)  loss_bbox_aux_4: 0.1247 (0.1287)  loss_bbox_dn_0: 0.1496 (0.1538)  loss_bbox_dn_1: 0.1296 (0.1268)  loss_bbox_dn_2: 0.1244 (0.1229)  loss_bbox_dn_3: 0.1210 (0.1204)  loss_bbox_dn_4: 0.1206 (0.1194)  loss_bbox_dn_5: 0.1206 (0.1194)  loss_bbox_enc_0: 0.1521 (0.1527)  loss_giou: 0.3107 (0.3135)  loss_giou_aux_0: 0.3256 (0.3219)  loss_giou_aux_1: 0.3145 (0.3158)  loss_giou_aux_2: 0.3127 (0.3138)  loss_giou_aux_3: 0.3108 (0.3129)  loss_giou_aux_4: 0.3107 (0.3134)  loss_giou_dn_0: 0.3320 (0.3378)  loss_giou_dn_1: 0.2774 (0.2833)  loss_giou_dn_2: 0.2708 (0.2766)  loss_giou_dn_3: 0.2697 (0.2750)  loss_giou_dn_4: 0.2690 (0.2745)  loss_giou_dn_5: 0.2690 (0.2745)  loss_giou_enc_0: 0.3657 (0.3689)  loss_vfl: 0.3747 (0.3755)  loss_vfl_aux_0: 0.4468 (0.4608)  loss_vfl_aux_1: 0.4088 (0.4055)  loss_vfl_aux_2: 0.3886 (0.3866)  loss_vfl_aux_3: 0.3883 (0.3800)  loss_vfl_aux_4: 0.3807 (0.3759)  loss_vfl_dn_0: 0.3564 (0.3554)  loss_vfl_dn_1: 0.3188 (0.3211)  loss_vfl_dn_2: 0.3146 (0.3168)  loss_vfl_dn_3: 0.3139 (0.3157)  loss_vfl_dn_4: 0.3139 (0.3152)  loss_vfl_dn_5: 0.3141 (0.3152)  loss_vfl_enc_0: 0.4785 (0.4801)  time: 0.4985  data: 0.0097  max mem: 5639
Epoch: [2]  [ 700/1519]  eta: 0:07:35  lr: 0.000004  lr2: 0.000040  loss: 10.1599 (10.4836)  loss_bbox: 0.1213 (0.1290)  loss_bbox_aux_0: 0.1280 (0.1332)  loss_bbox_aux_1: 0.1248 (0.1299)  loss_bbox_aux_2: 0.1198 (0.1288)  loss_bbox_aux_3: 0.1209 (0.1286)  loss_bbox_aux_4: 0.1213 (0.1290)  loss_bbox_dn_0: 0.1442 (0.1542)  loss_bbox_dn_1: 0.1223 (0.1271)  loss_bbox_dn_2: 0.1173 (0.1232)  loss_bbox_dn_3: 0.1123 (0.1207)  loss_bbox_dn_4: 0.1109 (0.1197)  loss_bbox_dn_5: 0.1109 (0.1197)  loss_bbox_enc_0: 0.1489 (0.1532)  loss_giou: 0.3086 (0.3137)  loss_giou_aux_0: 0.3132 (0.3220)  loss_giou_aux_1: 0.3152 (0.3159)  loss_giou_aux_2: 0.3123 (0.3139)  loss_giou_aux_3: 0.3099 (0.3131)  loss_giou_aux_4: 0.3086 (0.3135)  loss_giou_dn_0: 0.3357 (0.3380)  loss_giou_dn_1: 0.2780 (0.2835)  loss_giou_dn_2: 0.2714 (0.2768)  loss_giou_dn_3: 0.2705 (0.2752)  loss_giou_dn_4: 0.2703 (0.2746)  loss_giou_dn_5: 0.2704 (0.2747)  loss_giou_enc_0: 0.3722 (0.3690)  loss_vfl: 0.3625 (0.3753)  loss_vfl_aux_0: 0.4373 (0.4601)  loss_vfl_aux_1: 0.3851 (0.4055)  loss_vfl_aux_2: 0.3712 (0.3869)  loss_vfl_aux_3: 0.3666 (0.3800)  loss_vfl_aux_4: 0.3626 (0.3759)  loss_vfl_dn_0: 0.3549 (0.3555)  loss_vfl_dn_1: 0.3187 (0.3212)  loss_vfl_dn_2: 0.3151 (0.3169)  loss_vfl_dn_3: 0.3146 (0.3158)  loss_vfl_dn_4: 0.3137 (0.3153)  loss_vfl_dn_5: 0.3137 (0.3153)  loss_vfl_enc_0: 0.4677 (0.4800)  time: 0.4923  data: 0.0098  max mem: 5639
Epoch: [2]  [ 800/1519]  eta: 0:06:35  lr: 0.000004  lr2: 0.000040  loss: 10.3564 (10.4823)  loss_bbox: 0.1215 (0.1293)  loss_bbox_aux_0: 0.1306 (0.1335)  loss_bbox_aux_1: 0.1260 (0.1301)  loss_bbox_aux_2: 0.1228 (0.1290)  loss_bbox_aux_3: 0.1212 (0.1289)  loss_bbox_aux_4: 0.1215 (0.1293)  loss_bbox_dn_0: 0.1454 (0.1544)  loss_bbox_dn_1: 0.1195 (0.1273)  loss_bbox_dn_2: 0.1160 (0.1234)  loss_bbox_dn_3: 0.1128 (0.1209)  loss_bbox_dn_4: 0.1112 (0.1199)  loss_bbox_dn_5: 0.1112 (0.1199)  loss_bbox_enc_0: 0.1509 (0.1532)  loss_giou: 0.3225 (0.3138)  loss_giou_aux_0: 0.3321 (0.3221)  loss_giou_aux_1: 0.3245 (0.3159)  loss_giou_aux_2: 0.3246 (0.3139)  loss_giou_aux_3: 0.3217 (0.3132)  loss_giou_aux_4: 0.3226 (0.3137)  loss_giou_dn_0: 0.3471 (0.3378)  loss_giou_dn_1: 0.2889 (0.2833)  loss_giou_dn_2: 0.2806 (0.2766)  loss_giou_dn_3: 0.2794 (0.2750)  loss_giou_dn_4: 0.2791 (0.2745)  loss_giou_dn_5: 0.2791 (0.2746)  loss_giou_enc_0: 0.3699 (0.3688)  loss_vfl: 0.3686 (0.3749)  loss_vfl_aux_0: 0.4470 (0.4591)  loss_vfl_aux_1: 0.3933 (0.4051)  loss_vfl_aux_2: 0.3779 (0.3866)  loss_vfl_aux_3: 0.3788 (0.3796)  loss_vfl_aux_4: 0.3682 (0.3755)  loss_vfl_dn_0: 0.3573 (0.3554)  loss_vfl_dn_1: 0.3230 (0.3212)  loss_vfl_dn_2: 0.3184 (0.3168)  loss_vfl_dn_3: 0.3173 (0.3157)  loss_vfl_dn_4: 0.3167 (0.3153)  loss_vfl_dn_5: 0.3168 (0.3152)  loss_vfl_enc_0: 0.4600 (0.4793)  time: 0.4996  data: 0.0097  max mem: 5639
Epoch: [2]  [ 900/1519]  eta: 0:05:38  lr: 0.000004  lr2: 0.000040  loss: 10.5310 (10.4820)  loss_bbox: 0.1293 (0.1294)  loss_bbox_aux_0: 0.1256 (0.1336)  loss_bbox_aux_1: 0.1311 (0.1303)  loss_bbox_aux_2: 0.1293 (0.1291)  loss_bbox_aux_3: 0.1307 (0.1290)  loss_bbox_aux_4: 0.1293 (0.1294)  loss_bbox_dn_0: 0.1560 (0.1546)  loss_bbox_dn_1: 0.1272 (0.1274)  loss_bbox_dn_2: 0.1222 (0.1236)  loss_bbox_dn_3: 0.1187 (0.1211)  loss_bbox_dn_4: 0.1167 (0.1201)  loss_bbox_dn_5: 0.1167 (0.1201)  loss_bbox_enc_0: 0.1400 (0.1530)  loss_giou: 0.3005 (0.3138)  loss_giou_aux_0: 0.3102 (0.3221)  loss_giou_aux_1: 0.3056 (0.3160)  loss_giou_aux_2: 0.3027 (0.3139)  loss_giou_aux_3: 0.3005 (0.3132)  loss_giou_aux_4: 0.3006 (0.3137)  loss_giou_dn_0: 0.3258 (0.3377)  loss_giou_dn_1: 0.2709 (0.2833)  loss_giou_dn_2: 0.2642 (0.2766)  loss_giou_dn_3: 0.2628 (0.2750)  loss_giou_dn_4: 0.2631 (0.2745)  loss_giou_dn_5: 0.2632 (0.2745)  loss_giou_enc_0: 0.3494 (0.3685)  loss_vfl: 0.3818 (0.3749)  loss_vfl_aux_0: 0.4634 (0.4587)  loss_vfl_aux_1: 0.4095 (0.4046)  loss_vfl_aux_2: 0.3916 (0.3866)  loss_vfl_aux_3: 0.3875 (0.3797)  loss_vfl_aux_4: 0.3828 (0.3754)  loss_vfl_dn_0: 0.3518 (0.3554)  loss_vfl_dn_1: 0.3161 (0.3212)  loss_vfl_dn_2: 0.3123 (0.3168)  loss_vfl_dn_3: 0.3115 (0.3157)  loss_vfl_dn_4: 0.3111 (0.3153)  loss_vfl_dn_5: 0.3109 (0.3153)  loss_vfl_enc_0: 0.4758 (0.4790)  time: 0.5480  data: 0.0097  max mem: 5639
Epoch: [2]  [1000/1519]  eta: 0:04:44  lr: 0.000004  lr2: 0.000040  loss: 10.5691 (10.4803)  loss_bbox: 0.1251 (0.1295)  loss_bbox_aux_0: 0.1387 (0.1337)  loss_bbox_aux_1: 0.1289 (0.1304)  loss_bbox_aux_2: 0.1253 (0.1292)  loss_bbox_aux_3: 0.1252 (0.1291)  loss_bbox_aux_4: 0.1251 (0.1295)  loss_bbox_dn_0: 0.1531 (0.1548)  loss_bbox_dn_1: 0.1260 (0.1276)  loss_bbox_dn_2: 0.1236 (0.1238)  loss_bbox_dn_3: 0.1177 (0.1213)  loss_bbox_dn_4: 0.1176 (0.1203)  loss_bbox_dn_5: 0.1176 (0.1204)  loss_bbox_enc_0: 0.1514 (0.1533)  loss_giou: 0.3098 (0.3134)  loss_giou_aux_0: 0.3198 (0.3217)  loss_giou_aux_1: 0.3146 (0.3155)  loss_giou_aux_2: 0.3121 (0.3135)  loss_giou_aux_3: 0.3105 (0.3129)  loss_giou_aux_4: 0.3098 (0.3133)  loss_giou_dn_0: 0.3363 (0.3373)  loss_giou_dn_1: 0.2824 (0.2829)  loss_giou_dn_2: 0.2747 (0.2762)  loss_giou_dn_3: 0.2724 (0.2746)  loss_giou_dn_4: 0.2724 (0.2741)  loss_giou_dn_5: 0.2725 (0.2742)  loss_giou_enc_0: 0.3680 (0.3682)  loss_vfl: 0.3855 (0.3752)  loss_vfl_aux_0: 0.4483 (0.4587)  loss_vfl_aux_1: 0.4064 (0.4047)  loss_vfl_aux_2: 0.3895 (0.3869)  loss_vfl_aux_3: 0.3895 (0.3799)  loss_vfl_aux_4: 0.3853 (0.3757)  loss_vfl_dn_0: 0.3573 (0.3553)  loss_vfl_dn_1: 0.3249 (0.3211)  loss_vfl_dn_2: 0.3200 (0.3167)  loss_vfl_dn_3: 0.3185 (0.3156)  loss_vfl_dn_4: 0.3179 (0.3152)  loss_vfl_dn_5: 0.3179 (0.3152)  loss_vfl_enc_0: 0.4738 (0.4793)  time: 0.5307  data: 0.0100  max mem: 5639
Epoch: [2]  [1100/1519]  eta: 0:03:48  lr: 0.000004  lr2: 0.000040  loss: 10.5210 (10.4778)  loss_bbox: 0.1266 (0.1295)  loss_bbox_aux_0: 0.1305 (0.1338)  loss_bbox_aux_1: 0.1272 (0.1304)  loss_bbox_aux_2: 0.1251 (0.1294)  loss_bbox_aux_3: 0.1249 (0.1292)  loss_bbox_aux_4: 0.1266 (0.1295)  loss_bbox_dn_0: 0.1489 (0.1548)  loss_bbox_dn_1: 0.1210 (0.1275)  loss_bbox_dn_2: 0.1168 (0.1237)  loss_bbox_dn_3: 0.1156 (0.1212)  loss_bbox_dn_4: 0.1142 (0.1203)  loss_bbox_dn_5: 0.1142 (0.1203)  loss_bbox_enc_0: 0.1546 (0.1533)  loss_giou: 0.3219 (0.3135)  loss_giou_aux_0: 0.3342 (0.3219)  loss_giou_aux_1: 0.3367 (0.3156)  loss_giou_aux_2: 0.3210 (0.3136)  loss_giou_aux_3: 0.3220 (0.3129)  loss_giou_aux_4: 0.3226 (0.3134)  loss_giou_dn_0: 0.3485 (0.3371)  loss_giou_dn_1: 0.2905 (0.2828)  loss_giou_dn_2: 0.2806 (0.2761)  loss_giou_dn_3: 0.2794 (0.2745)  loss_giou_dn_4: 0.2785 (0.2740)  loss_giou_dn_5: 0.2787 (0.2741)  loss_giou_enc_0: 0.3827 (0.3681)  loss_vfl: 0.3782 (0.3750)  loss_vfl_aux_0: 0.4699 (0.4580)  loss_vfl_aux_1: 0.4067 (0.4044)  loss_vfl_aux_2: 0.3896 (0.3867)  loss_vfl_aux_3: 0.3843 (0.3799)  loss_vfl_aux_4: 0.3781 (0.3756)  loss_vfl_dn_0: 0.3604 (0.3552)  loss_vfl_dn_1: 0.3257 (0.3210)  loss_vfl_dn_2: 0.3214 (0.3167)  loss_vfl_dn_3: 0.3202 (0.3156)  loss_vfl_dn_4: 0.3195 (0.3151)  loss_vfl_dn_5: 0.3192 (0.3151)  loss_vfl_enc_0: 0.4883 (0.4789)  time: 0.5340  data: 0.0102  max mem: 5639
Epoch: [2]  [1200/1519]  eta: 0:02:53  lr: 0.000004  lr2: 0.000040  loss: 10.4288 (10.4735)  loss_bbox: 0.1235 (0.1294)  loss_bbox_aux_0: 0.1296 (0.1337)  loss_bbox_aux_1: 0.1260 (0.1302)  loss_bbox_aux_2: 0.1216 (0.1292)  loss_bbox_aux_3: 0.1229 (0.1290)  loss_bbox_aux_4: 0.1235 (0.1295)  loss_bbox_dn_0: 0.1485 (0.1546)  loss_bbox_dn_1: 0.1213 (0.1274)  loss_bbox_dn_2: 0.1151 (0.1235)  loss_bbox_dn_3: 0.1138 (0.1210)  loss_bbox_dn_4: 0.1137 (0.1200)  loss_bbox_dn_5: 0.1138 (0.1201)  loss_bbox_enc_0: 0.1489 (0.1531)  loss_giou: 0.3151 (0.3136)  loss_giou_aux_0: 0.3231 (0.3218)  loss_giou_aux_1: 0.3187 (0.3156)  loss_giou_aux_2: 0.3135 (0.3136)  loss_giou_aux_3: 0.3160 (0.3130)  loss_giou_aux_4: 0.3148 (0.3135)  loss_giou_dn_0: 0.3444 (0.3372)  loss_giou_dn_1: 0.2881 (0.2828)  loss_giou_dn_2: 0.2812 (0.2761)  loss_giou_dn_3: 0.2797 (0.2745)  loss_giou_dn_4: 0.2794 (0.2740)  loss_giou_dn_5: 0.2797 (0.2740)  loss_giou_enc_0: 0.3720 (0.3680)  loss_vfl: 0.3793 (0.3748)  loss_vfl_aux_0: 0.4559 (0.4580)  loss_vfl_aux_1: 0.4112 (0.4040)  loss_vfl_aux_2: 0.3905 (0.3866)  loss_vfl_aux_3: 0.3794 (0.3796)  loss_vfl_aux_4: 0.3795 (0.3753)  loss_vfl_dn_0: 0.3541 (0.3551)  loss_vfl_dn_1: 0.3201 (0.3209)  loss_vfl_dn_2: 0.3167 (0.3166)  loss_vfl_dn_3: 0.3151 (0.3155)  loss_vfl_dn_4: 0.3147 (0.3150)  loss_vfl_dn_5: 0.3151 (0.3150)  loss_vfl_enc_0: 0.4792 (0.4789)  time: 0.5487  data: 0.0101  max mem: 5639
Epoch: [2]  [1300/1519]  eta: 0:01:58  lr: 0.000004  lr2: 0.000040  loss: 10.3457 (10.4746)  loss_bbox: 0.1277 (0.1298)  loss_bbox_aux_0: 0.1299 (0.1339)  loss_bbox_aux_1: 0.1291 (0.1306)  loss_bbox_aux_2: 0.1281 (0.1295)  loss_bbox_aux_3: 0.1282 (0.1293)  loss_bbox_aux_4: 0.1277 (0.1298)  loss_bbox_dn_0: 0.1345 (0.1547)  loss_bbox_dn_1: 0.1132 (0.1275)  loss_bbox_dn_2: 0.1102 (0.1236)  loss_bbox_dn_3: 0.1105 (0.1211)  loss_bbox_dn_4: 0.1105 (0.1201)  loss_bbox_dn_5: 0.1105 (0.1201)  loss_bbox_enc_0: 0.1410 (0.1534)  loss_giou: 0.3032 (0.3137)  loss_giou_aux_0: 0.3088 (0.3218)  loss_giou_aux_1: 0.3087 (0.3156)  loss_giou_aux_2: 0.3055 (0.3136)  loss_giou_aux_3: 0.3006 (0.3131)  loss_giou_aux_4: 0.3031 (0.3136)  loss_giou_dn_0: 0.3276 (0.3370)  loss_giou_dn_1: 0.2739 (0.2828)  loss_giou_dn_2: 0.2684 (0.2761)  loss_giou_dn_3: 0.2676 (0.2745)  loss_giou_dn_4: 0.2670 (0.2740)  loss_giou_dn_5: 0.2669 (0.2741)  loss_giou_enc_0: 0.3495 (0.3679)  loss_vfl: 0.3666 (0.3747)  loss_vfl_aux_0: 0.4472 (0.4578)  loss_vfl_aux_1: 0.3876 (0.4037)  loss_vfl_aux_2: 0.3840 (0.3864)  loss_vfl_aux_3: 0.3731 (0.3795)  loss_vfl_aux_4: 0.3685 (0.3751)  loss_vfl_dn_0: 0.3542 (0.3550)  loss_vfl_dn_1: 0.3233 (0.3209)  loss_vfl_dn_2: 0.3192 (0.3166)  loss_vfl_dn_3: 0.3179 (0.3155)  loss_vfl_dn_4: 0.3172 (0.3150)  loss_vfl_dn_5: 0.3173 (0.3150)  loss_vfl_enc_0: 0.4747 (0.4784)  time: 0.5828  data: 0.0101  max mem: 5639
Epoch: [2]  [1400/1519]  eta: 0:01:04  lr: 0.000004  lr2: 0.000040  loss: 10.4238 (10.4743)  loss_bbox: 0.1299 (0.1298)  loss_bbox_aux_0: 0.1323 (0.1341)  loss_bbox_aux_1: 0.1314 (0.1307)  loss_bbox_aux_2: 0.1303 (0.1296)  loss_bbox_aux_3: 0.1310 (0.1294)  loss_bbox_aux_4: 0.1301 (0.1299)  loss_bbox_dn_0: 0.1501 (0.1548)  loss_bbox_dn_1: 0.1231 (0.1275)  loss_bbox_dn_2: 0.1194 (0.1237)  loss_bbox_dn_3: 0.1176 (0.1212)  loss_bbox_dn_4: 0.1164 (0.1202)  loss_bbox_dn_5: 0.1165 (0.1202)  loss_bbox_enc_0: 0.1532 (0.1535)  loss_giou: 0.3236 (0.3137)  loss_giou_aux_0: 0.3237 (0.3218)  loss_giou_aux_1: 0.3261 (0.3156)  loss_giou_aux_2: 0.3246 (0.3137)  loss_giou_aux_3: 0.3240 (0.3131)  loss_giou_aux_4: 0.3235 (0.3137)  loss_giou_dn_0: 0.3352 (0.3370)  loss_giou_dn_1: 0.2856 (0.2827)  loss_giou_dn_2: 0.2784 (0.2761)  loss_giou_dn_3: 0.2777 (0.2745)  loss_giou_dn_4: 0.2775 (0.2740)  loss_giou_dn_5: 0.2777 (0.2740)  loss_giou_enc_0: 0.3676 (0.3678)  loss_vfl: 0.3716 (0.3746)  loss_vfl_aux_0: 0.4493 (0.4574)  loss_vfl_aux_1: 0.3844 (0.4034)  loss_vfl_aux_2: 0.3835 (0.3862)  loss_vfl_aux_3: 0.3739 (0.3794)  loss_vfl_aux_4: 0.3704 (0.3751)  loss_vfl_dn_0: 0.3580 (0.3550)  loss_vfl_dn_1: 0.3226 (0.3209)  loss_vfl_dn_2: 0.3183 (0.3166)  loss_vfl_dn_3: 0.3171 (0.3155)  loss_vfl_dn_4: 0.3172 (0.3150)  loss_vfl_dn_5: 0.3170 (0.3150)  loss_vfl_enc_0: 0.4599 (0.4781)  time: 0.4960  data: 0.0102  max mem: 5639
Epoch: [2]  [1500/1519]  eta: 0:00:10  lr: 0.000004  lr2: 0.000040  loss: 10.3074 (10.4704)  loss_bbox: 0.1237 (0.1297)  loss_bbox_aux_0: 0.1286 (0.1341)  loss_bbox_aux_1: 0.1243 (0.1307)  loss_bbox_aux_2: 0.1248 (0.1297)  loss_bbox_aux_3: 0.1227 (0.1293)  loss_bbox_aux_4: 0.1228 (0.1297)  loss_bbox_dn_0: 0.1443 (0.1547)  loss_bbox_dn_1: 0.1218 (0.1275)  loss_bbox_dn_2: 0.1179 (0.1237)  loss_bbox_dn_3: 0.1143 (0.1212)  loss_bbox_dn_4: 0.1136 (0.1202)  loss_bbox_dn_5: 0.1136 (0.1202)  loss_bbox_enc_0: 0.1468 (0.1534)  loss_giou: 0.3097 (0.3134)  loss_giou_aux_0: 0.3197 (0.3216)  loss_giou_aux_1: 0.3101 (0.3154)  loss_giou_aux_2: 0.3048 (0.3135)  loss_giou_aux_3: 0.3044 (0.3129)  loss_giou_aux_4: 0.3074 (0.3133)  loss_giou_dn_0: 0.3330 (0.3367)  loss_giou_dn_1: 0.2771 (0.2826)  loss_giou_dn_2: 0.2718 (0.2760)  loss_giou_dn_3: 0.2718 (0.2743)  loss_giou_dn_4: 0.2715 (0.2738)  loss_giou_dn_5: 0.2715 (0.2739)  loss_giou_enc_0: 0.3700 (0.3676)  loss_vfl: 0.3696 (0.3749)  loss_vfl_aux_0: 0.4461 (0.4572)  loss_vfl_aux_1: 0.3998 (0.4032)  loss_vfl_aux_2: 0.3710 (0.3861)  loss_vfl_aux_3: 0.3718 (0.3795)  loss_vfl_aux_4: 0.3703 (0.3753)  loss_vfl_dn_0: 0.3535 (0.3549)  loss_vfl_dn_1: 0.3176 (0.3208)  loss_vfl_dn_2: 0.3140 (0.3165)  loss_vfl_dn_3: 0.3126 (0.3154)  loss_vfl_dn_4: 0.3122 (0.3149)  loss_vfl_dn_5: 0.3124 (0.3149)  loss_vfl_enc_0: 0.4621 (0.4780)  time: 0.5045  data: 0.0092  max mem: 5639
Epoch: [2]  [1518/1519]  eta: 0:00:00  lr: 0.000004  lr2: 0.000040  loss: 10.3617 (10.4705)  loss_bbox: 0.1301 (0.1297)  loss_bbox_aux_0: 0.1380 (0.1341)  loss_bbox_aux_1: 0.1330 (0.1307)  loss_bbox_aux_2: 0.1343 (0.1297)  loss_bbox_aux_3: 0.1323 (0.1294)  loss_bbox_aux_4: 0.1302 (0.1298)  loss_bbox_dn_0: 0.1489 (0.1547)  loss_bbox_dn_1: 0.1221 (0.1275)  loss_bbox_dn_2: 0.1186 (0.1237)  loss_bbox_dn_3: 0.1165 (0.1211)  loss_bbox_dn_4: 0.1162 (0.1202)  loss_bbox_dn_5: 0.1163 (0.1202)  loss_bbox_enc_0: 0.1603 (0.1535)  loss_giou: 0.3143 (0.3134)  loss_giou_aux_0: 0.3215 (0.3217)  loss_giou_aux_1: 0.3151 (0.3154)  loss_giou_aux_2: 0.3135 (0.3135)  loss_giou_aux_3: 0.3164 (0.3129)  loss_giou_aux_4: 0.3154 (0.3134)  loss_giou_dn_0: 0.3338 (0.3367)  loss_giou_dn_1: 0.2799 (0.2826)  loss_giou_dn_2: 0.2723 (0.2760)  loss_giou_dn_3: 0.2705 (0.2743)  loss_giou_dn_4: 0.2697 (0.2738)  loss_giou_dn_5: 0.2697 (0.2739)  loss_giou_enc_0: 0.3697 (0.3677)  loss_vfl: 0.3546 (0.3748)  loss_vfl_aux_0: 0.4306 (0.4571)  loss_vfl_aux_1: 0.3778 (0.4030)  loss_vfl_aux_2: 0.3616 (0.3859)  loss_vfl_aux_3: 0.3560 (0.3794)  loss_vfl_aux_4: 0.3561 (0.3753)  loss_vfl_dn_0: 0.3534 (0.3549)  loss_vfl_dn_1: 0.3214 (0.3208)  loss_vfl_dn_2: 0.3177 (0.3165)  loss_vfl_dn_3: 0.3167 (0.3154)  loss_vfl_dn_4: 0.3161 (0.3149)  loss_vfl_dn_5: 0.3162 (0.3149)  loss_vfl_enc_0: 0.4590 (0.4779)  time: 0.4795  data: 0.0081  max mem: 5639
Epoch: [2] Total time: 0:13:38 (0.5388 s / it)
Averaged stats: lr: 0.000004  lr2: 0.000040  loss: 10.3617 (10.4705)  loss_bbox: 0.1301 (0.1297)  loss_bbox_aux_0: 0.1380 (0.1341)  loss_bbox_aux_1: 0.1330 (0.1307)  loss_bbox_aux_2: 0.1343 (0.1297)  loss_bbox_aux_3: 0.1323 (0.1294)  loss_bbox_aux_4: 0.1302 (0.1298)  loss_bbox_dn_0: 0.1489 (0.1547)  loss_bbox_dn_1: 0.1221 (0.1275)  loss_bbox_dn_2: 0.1186 (0.1237)  loss_bbox_dn_3: 0.1165 (0.1211)  loss_bbox_dn_4: 0.1162 (0.1202)  loss_bbox_dn_5: 0.1163 (0.1202)  loss_bbox_enc_0: 0.1603 (0.1535)  loss_giou: 0.3143 (0.3134)  loss_giou_aux_0: 0.3215 (0.3217)  loss_giou_aux_1: 0.3151 (0.3154)  loss_giou_aux_2: 0.3135 (0.3135)  loss_giou_aux_3: 0.3164 (0.3129)  loss_giou_aux_4: 0.3154 (0.3134)  loss_giou_dn_0: 0.3338 (0.3367)  loss_giou_dn_1: 0.2799 (0.2826)  loss_giou_dn_2: 0.2723 (0.2760)  loss_giou_dn_3: 0.2705 (0.2743)  loss_giou_dn_4: 0.2697 (0.2738)  loss_giou_dn_5: 0.2697 (0.2739)  loss_giou_enc_0: 0.3697 (0.3677)  loss_vfl: 0.3546 (0.3748)  loss_vfl_aux_0: 0.4306 (0.4571)  loss_vfl_aux_1: 0.3778 (0.4030)  loss_vfl_aux_2: 0.3616 (0.3859)  loss_vfl_aux_3: 0.3560 (0.3794)  loss_vfl_aux_4: 0.3561 (0.3753)  loss_vfl_dn_0: 0.3534 (0.3549)  loss_vfl_dn_1: 0.3214 (0.3208)  loss_vfl_dn_2: 0.3177 (0.3165)  loss_vfl_dn_3: 0.3167 (0.3154)  loss_vfl_dn_4: 0.3161 (0.3149)  loss_vfl_dn_5: 0.3162 (0.3149)  loss_vfl_enc_0: 0.4590 (0.4779)
Test:  [  0/165]  eta: 0:06:48    time: 2.4761  data: 2.2381  max mem: 5639
Test:  [ 10/165]  eta: 0:01:08    time: 0.4433  data: 0.2347  max mem: 5639
Test:  [ 20/165]  eta: 0:00:50    time: 0.2391  data: 0.0323  max mem: 5639
Test:  [ 30/165]  eta: 0:00:44    time: 0.2620  data: 0.0236  max mem: 5639
Test:  [ 40/165]  eta: 0:00:38    time: 0.2665  data: 0.0264  max mem: 5639
Test:  [ 50/165]  eta: 0:00:33    time: 0.2382  data: 0.0273  max mem: 5639
Test:  [ 60/165]  eta: 0:00:30    time: 0.2570  data: 0.0488  max mem: 5639
Test:  [ 70/165]  eta: 0:00:27    time: 0.2669  data: 0.0576  max mem: 5639
Test:  [ 80/165]  eta: 0:00:24    time: 0.2606  data: 0.0258  max mem: 5639
Test:  [ 90/165]  eta: 0:00:20    time: 0.2530  data: 0.0238  max mem: 5639
Test:  [100/165]  eta: 0:00:17    time: 0.2326  data: 0.0303  max mem: 5639
Test:  [110/165]  eta: 0:00:14    time: 0.2496  data: 0.0226  max mem: 5639
Test:  [120/165]  eta: 0:00:12    time: 0.2503  data: 0.0253  max mem: 5639
Test:  [130/165]  eta: 0:00:09    time: 0.2455  data: 0.0253  max mem: 5639
Test:  [140/165]  eta: 0:00:06    time: 0.2405  data: 0.0215  max mem: 5639
Test:  [150/165]  eta: 0:00:03    time: 0.2231  data: 0.0273  max mem: 5639
Test:  [160/165]  eta: 0:00:01    time: 0.2399  data: 0.0218  max mem: 5639
Test:  [164/165]  eta: 0:00:00    time: 0.2323  data: 0.0231  max mem: 5639
Test: Total time: 0:00:43 (0.2609 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=28.40s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
best_stat: {'epoch': 0, 'coco_eval_bbox': 0.4708596759809729}
Epoch: [3]  [   0/1519]  eta: 3:23:46  lr: 0.000004  lr2: 0.000040  loss: 10.2564 (10.2564)  loss_bbox: 0.0981 (0.0981)  loss_bbox_aux_0: 0.1134 (0.1134)  loss_bbox_aux_1: 0.1083 (0.1083)  loss_bbox_aux_2: 0.1000 (0.1000)  loss_bbox_aux_3: 0.0992 (0.0992)  loss_bbox_aux_4: 0.0982 (0.0982)  loss_bbox_dn_0: 0.1425 (0.1425)  loss_bbox_dn_1: 0.1221 (0.1221)  loss_bbox_dn_2: 0.1181 (0.1181)  loss_bbox_dn_3: 0.1180 (0.1180)  loss_bbox_dn_4: 0.1177 (0.1177)  loss_bbox_dn_5: 0.1177 (0.1177)  loss_bbox_enc_0: 0.1336 (0.1336)  loss_giou: 0.3031 (0.3031)  loss_giou_aux_0: 0.3302 (0.3302)  loss_giou_aux_1: 0.3167 (0.3167)  loss_giou_aux_2: 0.3051 (0.3051)  loss_giou_aux_3: 0.3039 (0.3039)  loss_giou_aux_4: 0.3031 (0.3031)  loss_giou_dn_0: 0.3420 (0.3420)  loss_giou_dn_1: 0.2934 (0.2934)  loss_giou_dn_2: 0.2883 (0.2883)  loss_giou_dn_3: 0.2866 (0.2866)  loss_giou_dn_4: 0.2863 (0.2863)  loss_giou_dn_5: 0.2863 (0.2863)  loss_giou_enc_0: 0.3770 (0.3770)  loss_vfl: 0.3717 (0.3717)  loss_vfl_aux_0: 0.4428 (0.4428)  loss_vfl_aux_1: 0.3994 (0.3994)  loss_vfl_aux_2: 0.4026 (0.4026)  loss_vfl_aux_3: 0.3744 (0.3744)  loss_vfl_aux_4: 0.3736 (0.3736)  loss_vfl_dn_0: 0.3481 (0.3481)  loss_vfl_dn_1: 0.3180 (0.3180)  loss_vfl_dn_2: 0.3126 (0.3126)  loss_vfl_dn_3: 0.3116 (0.3116)  loss_vfl_dn_4: 0.3116 (0.3116)  loss_vfl_dn_5: 0.3113 (0.3113)  loss_vfl_enc_0: 0.4699 (0.4699)  time: 8.0493  data: 5.1186  max mem: 5639
Epoch: [3]  [ 100/1519]  eta: 0:15:40  lr: 0.000004  lr2: 0.000040  loss: 10.1518 (10.3026)  loss_bbox: 0.1275 (0.1242)  loss_bbox_aux_0: 0.1368 (0.1308)  loss_bbox_aux_1: 0.1324 (0.1264)  loss_bbox_aux_2: 0.1290 (0.1248)  loss_bbox_aux_3: 0.1232 (0.1238)  loss_bbox_aux_4: 0.1267 (0.1240)  loss_bbox_dn_0: 0.1537 (0.1507)  loss_bbox_dn_1: 0.1249 (0.1240)  loss_bbox_dn_2: 0.1186 (0.1202)  loss_bbox_dn_3: 0.1192 (0.1175)  loss_bbox_dn_4: 0.1183 (0.1164)  loss_bbox_dn_5: 0.1184 (0.1164)  loss_bbox_enc_0: 0.1551 (0.1509)  loss_giou: 0.3002 (0.3075)  loss_giou_aux_0: 0.3091 (0.3167)  loss_giou_aux_1: 0.3053 (0.3097)  loss_giou_aux_2: 0.3020 (0.3079)  loss_giou_aux_3: 0.2971 (0.3070)  loss_giou_aux_4: 0.3002 (0.3069)  loss_giou_dn_0: 0.3191 (0.3310)  loss_giou_dn_1: 0.2710 (0.2778)  loss_giou_dn_2: 0.2634 (0.2716)  loss_giou_dn_3: 0.2604 (0.2699)  loss_giou_dn_4: 0.2599 (0.2693)  loss_giou_dn_5: 0.2600 (0.2694)  loss_giou_enc_0: 0.3547 (0.3631)  loss_vfl: 0.3711 (0.3722)  loss_vfl_aux_0: 0.4444 (0.4496)  loss_vfl_aux_1: 0.3812 (0.3979)  loss_vfl_aux_2: 0.3735 (0.3818)  loss_vfl_aux_3: 0.3708 (0.3756)  loss_vfl_aux_4: 0.3676 (0.3730)  loss_vfl_dn_0: 0.3477 (0.3526)  loss_vfl_dn_1: 0.3168 (0.3186)  loss_vfl_dn_2: 0.3122 (0.3143)  loss_vfl_dn_3: 0.3114 (0.3132)  loss_vfl_dn_4: 0.3106 (0.3126)  loss_vfl_dn_5: 0.3103 (0.3126)  loss_vfl_enc_0: 0.4688 (0.4709)  time: 0.6621  data: 0.0100  max mem: 5639
Epoch: [3]  [ 200/1519]  eta: 0:12:55  lr: 0.000004  lr2: 0.000040  loss: 10.0620 (10.3190)  loss_bbox: 0.1262 (0.1272)  loss_bbox_aux_0: 0.1330 (0.1320)  loss_bbox_aux_1: 0.1265 (0.1286)  loss_bbox_aux_2: 0.1272 (0.1272)  loss_bbox_aux_3: 0.1265 (0.1267)  loss_bbox_aux_4: 0.1262 (0.1269)  loss_bbox_dn_0: 0.1480 (0.1510)  loss_bbox_dn_1: 0.1219 (0.1241)  loss_bbox_dn_2: 0.1187 (0.1204)  loss_bbox_dn_3: 0.1142 (0.1177)  loss_bbox_dn_4: 0.1117 (0.1166)  loss_bbox_dn_5: 0.1117 (0.1166)  loss_bbox_enc_0: 0.1459 (0.1523)  loss_giou: 0.3024 (0.3081)  loss_giou_aux_0: 0.3114 (0.3165)  loss_giou_aux_1: 0.3037 (0.3103)  loss_giou_aux_2: 0.3032 (0.3082)  loss_giou_aux_3: 0.3030 (0.3075)  loss_giou_aux_4: 0.3025 (0.3077)  loss_giou_dn_0: 0.3306 (0.3313)  loss_giou_dn_1: 0.2791 (0.2779)  loss_giou_dn_2: 0.2705 (0.2716)  loss_giou_dn_3: 0.2684 (0.2699)  loss_giou_dn_4: 0.2668 (0.2694)  loss_giou_dn_5: 0.2668 (0.2694)  loss_giou_enc_0: 0.3585 (0.3652)  loss_vfl: 0.3614 (0.3700)  loss_vfl_aux_0: 0.4537 (0.4527)  loss_vfl_aux_1: 0.3911 (0.3974)  loss_vfl_aux_2: 0.3676 (0.3806)  loss_vfl_aux_3: 0.3667 (0.3739)  loss_vfl_aux_4: 0.3620 (0.3707)  loss_vfl_dn_0: 0.3495 (0.3530)  loss_vfl_dn_1: 0.3158 (0.3186)  loss_vfl_dn_2: 0.3115 (0.3143)  loss_vfl_dn_3: 0.3104 (0.3132)  loss_vfl_dn_4: 0.3106 (0.3127)  loss_vfl_dn_5: 0.3104 (0.3127)  loss_vfl_enc_0: 0.4643 (0.4689)  time: 0.4963  data: 0.0101  max mem: 5639
Epoch: [3]  [ 300/1519]  eta: 0:11:33  lr: 0.000004  lr2: 0.000040  loss: 9.9903 (10.3513)  loss_bbox: 0.1254 (0.1280)  loss_bbox_aux_0: 0.1278 (0.1323)  loss_bbox_aux_1: 0.1305 (0.1295)  loss_bbox_aux_2: 0.1260 (0.1283)  loss_bbox_aux_3: 0.1260 (0.1277)  loss_bbox_aux_4: 0.1254 (0.1278)  loss_bbox_dn_0: 0.1528 (0.1524)  loss_bbox_dn_1: 0.1247 (0.1254)  loss_bbox_dn_2: 0.1190 (0.1217)  loss_bbox_dn_3: 0.1161 (0.1189)  loss_bbox_dn_4: 0.1143 (0.1179)  loss_bbox_dn_5: 0.1144 (0.1179)  loss_bbox_enc_0: 0.1462 (0.1533)  loss_giou: 0.3039 (0.3089)  loss_giou_aux_0: 0.3136 (0.3174)  loss_giou_aux_1: 0.3148 (0.3112)  loss_giou_aux_2: 0.3035 (0.3092)  loss_giou_aux_3: 0.3030 (0.3084)  loss_giou_aux_4: 0.3040 (0.3087)  loss_giou_dn_0: 0.3281 (0.3324)  loss_giou_dn_1: 0.2706 (0.2787)  loss_giou_dn_2: 0.2623 (0.2723)  loss_giou_dn_3: 0.2612 (0.2706)  loss_giou_dn_4: 0.2607 (0.2700)  loss_giou_dn_5: 0.2606 (0.2701)  loss_giou_enc_0: 0.3589 (0.3659)  loss_vfl: 0.3532 (0.3706)  loss_vfl_aux_0: 0.4437 (0.4542)  loss_vfl_aux_1: 0.3737 (0.3975)  loss_vfl_aux_2: 0.3590 (0.3802)  loss_vfl_aux_3: 0.3550 (0.3740)  loss_vfl_aux_4: 0.3533 (0.3712)  loss_vfl_dn_0: 0.3526 (0.3534)  loss_vfl_dn_1: 0.3187 (0.3190)  loss_vfl_dn_2: 0.3138 (0.3147)  loss_vfl_dn_3: 0.3125 (0.3136)  loss_vfl_dn_4: 0.3121 (0.3131)  loss_vfl_dn_5: 0.3117 (0.3131)  loss_vfl_enc_0: 0.4651 (0.4718)  time: 0.6862  data: 0.0097  max mem: 5639
Epoch: [3]  [ 400/1519]  eta: 0:10:27  lr: 0.000004  lr2: 0.000040  loss: 10.4124 (10.3801)  loss_bbox: 0.1327 (0.1286)  loss_bbox_aux_0: 0.1293 (0.1328)  loss_bbox_aux_1: 0.1208 (0.1299)  loss_bbox_aux_2: 0.1259 (0.1288)  loss_bbox_aux_3: 0.1282 (0.1284)  loss_bbox_aux_4: 0.1308 (0.1284)  loss_bbox_dn_0: 0.1521 (0.1533)  loss_bbox_dn_1: 0.1294 (0.1261)  loss_bbox_dn_2: 0.1257 (0.1223)  loss_bbox_dn_3: 0.1217 (0.1196)  loss_bbox_dn_4: 0.1199 (0.1185)  loss_bbox_dn_5: 0.1199 (0.1185)  loss_bbox_enc_0: 0.1458 (0.1538)  loss_giou: 0.3091 (0.3097)  loss_giou_aux_0: 0.3104 (0.3183)  loss_giou_aux_1: 0.3056 (0.3122)  loss_giou_aux_2: 0.3053 (0.3101)  loss_giou_aux_3: 0.3056 (0.3094)  loss_giou_aux_4: 0.3091 (0.3096)  loss_giou_dn_0: 0.3331 (0.3335)  loss_giou_dn_1: 0.2847 (0.2798)  loss_giou_dn_2: 0.2768 (0.2733)  loss_giou_dn_3: 0.2755 (0.2716)  loss_giou_dn_4: 0.2753 (0.2710)  loss_giou_dn_5: 0.2752 (0.2711)  loss_giou_enc_0: 0.3599 (0.3666)  loss_vfl: 0.3738 (0.3722)  loss_vfl_aux_0: 0.4406 (0.4537)  loss_vfl_aux_1: 0.4009 (0.3987)  loss_vfl_aux_2: 0.3853 (0.3816)  loss_vfl_aux_3: 0.3774 (0.3753)  loss_vfl_aux_4: 0.3727 (0.3728)  loss_vfl_dn_0: 0.3551 (0.3536)  loss_vfl_dn_1: 0.3229 (0.3193)  loss_vfl_dn_2: 0.3182 (0.3150)  loss_vfl_dn_3: 0.3167 (0.3139)  loss_vfl_dn_4: 0.3156 (0.3134)  loss_vfl_dn_5: 0.3157 (0.3134)  loss_vfl_enc_0: 0.4734 (0.4723)  time: 0.5554  data: 0.0101  max mem: 5639
Epoch: [3]  [ 500/1519]  eta: 0:09:25  lr: 0.000004  lr2: 0.000040  loss: 10.2702 (10.3668)  loss_bbox: 0.1235 (0.1279)  loss_bbox_aux_0: 0.1236 (0.1318)  loss_bbox_aux_1: 0.1239 (0.1290)  loss_bbox_aux_2: 0.1259 (0.1281)  loss_bbox_aux_3: 0.1279 (0.1278)  loss_bbox_aux_4: 0.1284 (0.1277)  loss_bbox_dn_0: 0.1463 (0.1521)  loss_bbox_dn_1: 0.1195 (0.1252)  loss_bbox_dn_2: 0.1140 (0.1214)  loss_bbox_dn_3: 0.1098 (0.1187)  loss_bbox_dn_4: 0.1097 (0.1177)  loss_bbox_dn_5: 0.1097 (0.1177)  loss_bbox_enc_0: 0.1447 (0.1524)  loss_giou: 0.3082 (0.3102)  loss_giou_aux_0: 0.3174 (0.3184)  loss_giou_aux_1: 0.3124 (0.3126)  loss_giou_aux_2: 0.3101 (0.3106)  loss_giou_aux_3: 0.3082 (0.3099)  loss_giou_aux_4: 0.3082 (0.3100)  loss_giou_dn_0: 0.3365 (0.3334)  loss_giou_dn_1: 0.2836 (0.2799)  loss_giou_dn_2: 0.2746 (0.2734)  loss_giou_dn_3: 0.2738 (0.2717)  loss_giou_dn_4: 0.2734 (0.2712)  loss_giou_dn_5: 0.2735 (0.2712)  loss_giou_enc_0: 0.3575 (0.3665)  loss_vfl: 0.3718 (0.3713)  loss_vfl_aux_0: 0.4532 (0.4526)  loss_vfl_aux_1: 0.3968 (0.3983)  loss_vfl_aux_2: 0.3778 (0.3811)  loss_vfl_aux_3: 0.3714 (0.3744)  loss_vfl_aux_4: 0.3719 (0.3719)  loss_vfl_dn_0: 0.3516 (0.3534)  loss_vfl_dn_1: 0.3194 (0.3194)  loss_vfl_dn_2: 0.3143 (0.3151)  loss_vfl_dn_3: 0.3131 (0.3140)  loss_vfl_dn_4: 0.3119 (0.3135)  loss_vfl_dn_5: 0.3120 (0.3135)  loss_vfl_enc_0: 0.4689 (0.4719)  time: 0.4999  data: 0.0098  max mem: 5639
Epoch: [3]  [ 600/1519]  eta: 0:08:27  lr: 0.000004  lr2: 0.000040  loss: 10.2825 (10.3658)  loss_bbox: 0.1264 (0.1279)  loss_bbox_aux_0: 0.1194 (0.1317)  loss_bbox_aux_1: 0.1221 (0.1290)  loss_bbox_aux_2: 0.1223 (0.1281)  loss_bbox_aux_3: 0.1256 (0.1277)  loss_bbox_aux_4: 0.1264 (0.1277)  loss_bbox_dn_0: 0.1481 (0.1519)  loss_bbox_dn_1: 0.1276 (0.1250)  loss_bbox_dn_2: 0.1237 (0.1212)  loss_bbox_dn_3: 0.1189 (0.1185)  loss_bbox_dn_4: 0.1145 (0.1175)  loss_bbox_dn_5: 0.1145 (0.1175)  loss_bbox_enc_0: 0.1360 (0.1523)  loss_giou: 0.3110 (0.3105)  loss_giou_aux_0: 0.3137 (0.3186)  loss_giou_aux_1: 0.3094 (0.3127)  loss_giou_aux_2: 0.3041 (0.3108)  loss_giou_aux_3: 0.3131 (0.3101)  loss_giou_aux_4: 0.3109 (0.3103)  loss_giou_dn_0: 0.3366 (0.3335)  loss_giou_dn_1: 0.2776 (0.2800)  loss_giou_dn_2: 0.2728 (0.2735)  loss_giou_dn_3: 0.2710 (0.2718)  loss_giou_dn_4: 0.2694 (0.2713)  loss_giou_dn_5: 0.2694 (0.2714)  loss_giou_enc_0: 0.3586 (0.3669)  loss_vfl: 0.3638 (0.3708)  loss_vfl_aux_0: 0.4363 (0.4525)  loss_vfl_aux_1: 0.3929 (0.3980)  loss_vfl_aux_2: 0.3801 (0.3807)  loss_vfl_aux_3: 0.3654 (0.3740)  loss_vfl_aux_4: 0.3647 (0.3714)  loss_vfl_dn_0: 0.3523 (0.3534)  loss_vfl_dn_1: 0.3192 (0.3194)  loss_vfl_dn_2: 0.3170 (0.3151)  loss_vfl_dn_3: 0.3161 (0.3140)  loss_vfl_dn_4: 0.3155 (0.3135)  loss_vfl_dn_5: 0.3156 (0.3135)  loss_vfl_enc_0: 0.4714 (0.4722)  time: 0.5436  data: 0.0097  max mem: 5639
Epoch: [3]  [ 700/1519]  eta: 0:07:29  lr: 0.000004  lr2: 0.000040  loss: 9.8577 (10.3439)  loss_bbox: 0.1207 (0.1277)  loss_bbox_aux_0: 0.1264 (0.1314)  loss_bbox_aux_1: 0.1236 (0.1287)  loss_bbox_aux_2: 0.1214 (0.1279)  loss_bbox_aux_3: 0.1206 (0.1275)  loss_bbox_aux_4: 0.1207 (0.1276)  loss_bbox_dn_0: 0.1379 (0.1516)  loss_bbox_dn_1: 0.1137 (0.1248)  loss_bbox_dn_2: 0.1116 (0.1211)  loss_bbox_dn_3: 0.1076 (0.1184)  loss_bbox_dn_4: 0.1068 (0.1173)  loss_bbox_dn_5: 0.1068 (0.1173)  loss_bbox_enc_0: 0.1408 (0.1518)  loss_giou: 0.2941 (0.3098)  loss_giou_aux_0: 0.3042 (0.3176)  loss_giou_aux_1: 0.2978 (0.3118)  loss_giou_aux_2: 0.2946 (0.3100)  loss_giou_aux_3: 0.2941 (0.3093)  loss_giou_aux_4: 0.2941 (0.3096)  loss_giou_dn_0: 0.3180 (0.3325)  loss_giou_dn_1: 0.2677 (0.2792)  loss_giou_dn_2: 0.2615 (0.2728)  loss_giou_dn_3: 0.2599 (0.2711)  loss_giou_dn_4: 0.2597 (0.2706)  loss_giou_dn_5: 0.2596 (0.2706)  loss_giou_enc_0: 0.3498 (0.3657)  loss_vfl: 0.3520 (0.3699)  loss_vfl_aux_0: 0.4157 (0.4511)  loss_vfl_aux_1: 0.3750 (0.3969)  loss_vfl_aux_2: 0.3602 (0.3798)  loss_vfl_aux_3: 0.3571 (0.3733)  loss_vfl_aux_4: 0.3529 (0.3706)  loss_vfl_dn_0: 0.3501 (0.3531)  loss_vfl_dn_1: 0.3163 (0.3191)  loss_vfl_dn_2: 0.3121 (0.3149)  loss_vfl_dn_3: 0.3115 (0.3138)  loss_vfl_dn_4: 0.3112 (0.3133)  loss_vfl_dn_5: 0.3111 (0.3133)  loss_vfl_enc_0: 0.4381 (0.4711)  time: 0.4844  data: 0.0101  max mem: 5639
Epoch: [3]  [ 800/1519]  eta: 0:06:33  lr: 0.000004  lr2: 0.000040  loss: 10.2717 (10.3468)  loss_bbox: 0.1239 (0.1280)  loss_bbox_aux_0: 0.1288 (0.1317)  loss_bbox_aux_1: 0.1272 (0.1290)  loss_bbox_aux_2: 0.1243 (0.1281)  loss_bbox_aux_3: 0.1243 (0.1279)  loss_bbox_aux_4: 0.1239 (0.1279)  loss_bbox_dn_0: 0.1373 (0.1516)  loss_bbox_dn_1: 0.1095 (0.1248)  loss_bbox_dn_2: 0.1083 (0.1211)  loss_bbox_dn_3: 0.1057 (0.1184)  loss_bbox_dn_4: 0.1063 (0.1173)  loss_bbox_dn_5: 0.1063 (0.1174)  loss_bbox_enc_0: 0.1453 (0.1524)  loss_giou: 0.3052 (0.3101)  loss_giou_aux_0: 0.3137 (0.3179)  loss_giou_aux_1: 0.3066 (0.3121)  loss_giou_aux_2: 0.3045 (0.3102)  loss_giou_aux_3: 0.3056 (0.3096)  loss_giou_aux_4: 0.3052 (0.3100)  loss_giou_dn_0: 0.3322 (0.3325)  loss_giou_dn_1: 0.2769 (0.2792)  loss_giou_dn_2: 0.2708 (0.2727)  loss_giou_dn_3: 0.2697 (0.2711)  loss_giou_dn_4: 0.2694 (0.2706)  loss_giou_dn_5: 0.2697 (0.2706)  loss_giou_enc_0: 0.3646 (0.3660)  loss_vfl: 0.3626 (0.3698)  loss_vfl_aux_0: 0.4429 (0.4508)  loss_vfl_aux_1: 0.4038 (0.3966)  loss_vfl_aux_2: 0.3792 (0.3797)  loss_vfl_aux_3: 0.3652 (0.3732)  loss_vfl_aux_4: 0.3620 (0.3704)  loss_vfl_dn_0: 0.3513 (0.3530)  loss_vfl_dn_1: 0.3144 (0.3191)  loss_vfl_dn_2: 0.3090 (0.3149)  loss_vfl_dn_3: 0.3079 (0.3138)  loss_vfl_dn_4: 0.3073 (0.3133)  loss_vfl_dn_5: 0.3072 (0.3133)  loss_vfl_enc_0: 0.4709 (0.4709)  time: 0.6144  data: 0.0099  max mem: 5639
Epoch: [3]  [ 900/1519]  eta: 0:05:36  lr: 0.000004  lr2: 0.000040  loss: 10.1136 (10.3391)  loss_bbox: 0.1213 (0.1280)  loss_bbox_aux_0: 0.1280 (0.1316)  loss_bbox_aux_1: 0.1247 (0.1290)  loss_bbox_aux_2: 0.1232 (0.1281)  loss_bbox_aux_3: 0.1214 (0.1279)  loss_bbox_aux_4: 0.1213 (0.1279)  loss_bbox_dn_0: 0.1459 (0.1515)  loss_bbox_dn_1: 0.1205 (0.1248)  loss_bbox_dn_2: 0.1152 (0.1210)  loss_bbox_dn_3: 0.1111 (0.1183)  loss_bbox_dn_4: 0.1097 (0.1173)  loss_bbox_dn_5: 0.1097 (0.1173)  loss_bbox_enc_0: 0.1467 (0.1523)  loss_giou: 0.2973 (0.3097)  loss_giou_aux_0: 0.3149 (0.3175)  loss_giou_aux_1: 0.3036 (0.3117)  loss_giou_aux_2: 0.3025 (0.3098)  loss_giou_aux_3: 0.2974 (0.3093)  loss_giou_aux_4: 0.2973 (0.3096)  loss_giou_dn_0: 0.3230 (0.3321)  loss_giou_dn_1: 0.2735 (0.2789)  loss_giou_dn_2: 0.2667 (0.2725)  loss_giou_dn_3: 0.2659 (0.2708)  loss_giou_dn_4: 0.2657 (0.2703)  loss_giou_dn_5: 0.2658 (0.2704)  loss_giou_enc_0: 0.3560 (0.3655)  loss_vfl: 0.3575 (0.3696)  loss_vfl_aux_0: 0.4312 (0.4503)  loss_vfl_aux_1: 0.3967 (0.3963)  loss_vfl_aux_2: 0.3695 (0.3795)  loss_vfl_aux_3: 0.3650 (0.3729)  loss_vfl_aux_4: 0.3592 (0.3702)  loss_vfl_dn_0: 0.3513 (0.3529)  loss_vfl_dn_1: 0.3182 (0.3190)  loss_vfl_dn_2: 0.3142 (0.3148)  loss_vfl_dn_3: 0.3124 (0.3136)  loss_vfl_dn_4: 0.3119 (0.3132)  loss_vfl_dn_5: 0.3123 (0.3132)  loss_vfl_enc_0: 0.4688 (0.4704)  time: 0.5835  data: 0.0108  max mem: 5639
Epoch: [3]  [1000/1519]  eta: 0:04:41  lr: 0.000004  lr2: 0.000040  loss: 10.2330 (10.3322)  loss_bbox: 0.1284 (0.1276)  loss_bbox_aux_0: 0.1331 (0.1314)  loss_bbox_aux_1: 0.1282 (0.1287)  loss_bbox_aux_2: 0.1232 (0.1278)  loss_bbox_aux_3: 0.1274 (0.1276)  loss_bbox_aux_4: 0.1284 (0.1276)  loss_bbox_dn_0: 0.1485 (0.1513)  loss_bbox_dn_1: 0.1231 (0.1246)  loss_bbox_dn_2: 0.1190 (0.1208)  loss_bbox_dn_3: 0.1151 (0.1181)  loss_bbox_dn_4: 0.1136 (0.1171)  loss_bbox_dn_5: 0.1137 (0.1171)  loss_bbox_enc_0: 0.1571 (0.1521)  loss_giou: 0.3014 (0.3093)  loss_giou_aux_0: 0.3029 (0.3172)  loss_giou_aux_1: 0.3003 (0.3113)  loss_giou_aux_2: 0.3016 (0.3095)  loss_giou_aux_3: 0.3014 (0.3090)  loss_giou_aux_4: 0.3014 (0.3092)  loss_giou_dn_0: 0.3219 (0.3318)  loss_giou_dn_1: 0.2696 (0.2786)  loss_giou_dn_2: 0.2645 (0.2723)  loss_giou_dn_3: 0.2638 (0.2706)  loss_giou_dn_4: 0.2633 (0.2701)  loss_giou_dn_5: 0.2633 (0.2701)  loss_giou_enc_0: 0.3543 (0.3651)  loss_vfl: 0.3611 (0.3699)  loss_vfl_aux_0: 0.4503 (0.4503)  loss_vfl_aux_1: 0.3908 (0.3965)  loss_vfl_aux_2: 0.3673 (0.3797)  loss_vfl_aux_3: 0.3650 (0.3731)  loss_vfl_aux_4: 0.3644 (0.3705)  loss_vfl_dn_0: 0.3483 (0.3528)  loss_vfl_dn_1: 0.3155 (0.3189)  loss_vfl_dn_2: 0.3105 (0.3147)  loss_vfl_dn_3: 0.3090 (0.3136)  loss_vfl_dn_4: 0.3087 (0.3131)  loss_vfl_dn_5: 0.3087 (0.3131)  loss_vfl_enc_0: 0.4529 (0.4704)  time: 0.4959  data: 0.0099  max mem: 5639
Epoch: [3]  [1100/1519]  eta: 0:03:45  lr: 0.000004  lr2: 0.000040  loss: 10.1497 (10.3263)  loss_bbox: 0.1173 (0.1274)  loss_bbox_aux_0: 0.1210 (0.1311)  loss_bbox_aux_1: 0.1180 (0.1285)  loss_bbox_aux_2: 0.1180 (0.1275)  loss_bbox_aux_3: 0.1176 (0.1274)  loss_bbox_aux_4: 0.1173 (0.1274)  loss_bbox_dn_0: 0.1357 (0.1509)  loss_bbox_dn_1: 0.1129 (0.1244)  loss_bbox_dn_2: 0.1092 (0.1206)  loss_bbox_dn_3: 0.1055 (0.1180)  loss_bbox_dn_4: 0.1046 (0.1169)  loss_bbox_dn_5: 0.1046 (0.1169)  loss_bbox_enc_0: 0.1371 (0.1518)  loss_giou: 0.3050 (0.3091)  loss_giou_aux_0: 0.3098 (0.3169)  loss_giou_aux_1: 0.3049 (0.3111)  loss_giou_aux_2: 0.3045 (0.3093)  loss_giou_aux_3: 0.3051 (0.3087)  loss_giou_aux_4: 0.3050 (0.3090)  loss_giou_dn_0: 0.3241 (0.3316)  loss_giou_dn_1: 0.2739 (0.2785)  loss_giou_dn_2: 0.2681 (0.2721)  loss_giou_dn_3: 0.2661 (0.2704)  loss_giou_dn_4: 0.2657 (0.2700)  loss_giou_dn_5: 0.2657 (0.2700)  loss_giou_enc_0: 0.3579 (0.3647)  loss_vfl: 0.3526 (0.3698)  loss_vfl_aux_0: 0.4471 (0.4501)  loss_vfl_aux_1: 0.3872 (0.3965)  loss_vfl_aux_2: 0.3616 (0.3796)  loss_vfl_aux_3: 0.3581 (0.3730)  loss_vfl_aux_4: 0.3570 (0.3704)  loss_vfl_dn_0: 0.3514 (0.3528)  loss_vfl_dn_1: 0.3184 (0.3189)  loss_vfl_dn_2: 0.3143 (0.3147)  loss_vfl_dn_3: 0.3131 (0.3136)  loss_vfl_dn_4: 0.3128 (0.3132)  loss_vfl_dn_5: 0.3125 (0.3132)  loss_vfl_enc_0: 0.4631 (0.4704)  time: 0.4909  data: 0.0106  max mem: 5639
Epoch: [3]  [1200/1519]  eta: 0:02:51  lr: 0.000004  lr2: 0.000040  loss: 10.0899 (10.3262)  loss_bbox: 0.1178 (0.1272)  loss_bbox_aux_0: 0.1224 (0.1309)  loss_bbox_aux_1: 0.1223 (0.1282)  loss_bbox_aux_2: 0.1201 (0.1272)  loss_bbox_aux_3: 0.1203 (0.1271)  loss_bbox_aux_4: 0.1178 (0.1271)  loss_bbox_dn_0: 0.1410 (0.1507)  loss_bbox_dn_1: 0.1124 (0.1241)  loss_bbox_dn_2: 0.1081 (0.1204)  loss_bbox_dn_3: 0.1042 (0.1177)  loss_bbox_dn_4: 0.1037 (0.1167)  loss_bbox_dn_5: 0.1037 (0.1167)  loss_bbox_enc_0: 0.1442 (0.1515)  loss_giou: 0.3132 (0.3093)  loss_giou_aux_0: 0.3207 (0.3171)  loss_giou_aux_1: 0.3180 (0.3113)  loss_giou_aux_2: 0.3137 (0.3095)  loss_giou_aux_3: 0.3135 (0.3089)  loss_giou_aux_4: 0.3131 (0.3092)  loss_giou_dn_0: 0.3330 (0.3319)  loss_giou_dn_1: 0.2768 (0.2787)  loss_giou_dn_2: 0.2738 (0.2723)  loss_giou_dn_3: 0.2726 (0.2706)  loss_giou_dn_4: 0.2720 (0.2701)  loss_giou_dn_5: 0.2720 (0.2702)  loss_giou_enc_0: 0.3724 (0.3649)  loss_vfl: 0.3539 (0.3698)  loss_vfl_aux_0: 0.4262 (0.4501)  loss_vfl_aux_1: 0.3813 (0.3967)  loss_vfl_aux_2: 0.3763 (0.3797)  loss_vfl_aux_3: 0.3594 (0.3731)  loss_vfl_aux_4: 0.3534 (0.3705)  loss_vfl_dn_0: 0.3530 (0.3528)  loss_vfl_dn_1: 0.3159 (0.3189)  loss_vfl_dn_2: 0.3120 (0.3147)  loss_vfl_dn_3: 0.3110 (0.3136)  loss_vfl_dn_4: 0.3107 (0.3131)  loss_vfl_dn_5: 0.3105 (0.3131)  loss_vfl_enc_0: 0.4527 (0.4705)  time: 0.6065  data: 0.0099  max mem: 5639
Epoch: [3]  [1300/1519]  eta: 0:01:58  lr: 0.000004  lr2: 0.000040  loss: 10.3291 (10.3289)  loss_bbox: 0.1334 (0.1276)  loss_bbox_aux_0: 0.1342 (0.1312)  loss_bbox_aux_1: 0.1348 (0.1286)  loss_bbox_aux_2: 0.1331 (0.1277)  loss_bbox_aux_3: 0.1330 (0.1275)  loss_bbox_aux_4: 0.1334 (0.1275)  loss_bbox_dn_0: 0.1565 (0.1510)  loss_bbox_dn_1: 0.1273 (0.1244)  loss_bbox_dn_2: 0.1249 (0.1207)  loss_bbox_dn_3: 0.1230 (0.1180)  loss_bbox_dn_4: 0.1225 (0.1169)  loss_bbox_dn_5: 0.1225 (0.1169)  loss_bbox_enc_0: 0.1566 (0.1517)  loss_giou: 0.3087 (0.3092)  loss_giou_aux_0: 0.3165 (0.3170)  loss_giou_aux_1: 0.3075 (0.3112)  loss_giou_aux_2: 0.3078 (0.3095)  loss_giou_aux_3: 0.3077 (0.3088)  loss_giou_aux_4: 0.3073 (0.3091)  loss_giou_dn_0: 0.3217 (0.3317)  loss_giou_dn_1: 0.2798 (0.2785)  loss_giou_dn_2: 0.2759 (0.2722)  loss_giou_dn_3: 0.2757 (0.2705)  loss_giou_dn_4: 0.2758 (0.2700)  loss_giou_dn_5: 0.2758 (0.2700)  loss_giou_enc_0: 0.3601 (0.3646)  loss_vfl: 0.3747 (0.3698)  loss_vfl_aux_0: 0.4571 (0.4504)  loss_vfl_aux_1: 0.4045 (0.3966)  loss_vfl_aux_2: 0.3752 (0.3796)  loss_vfl_aux_3: 0.3824 (0.3730)  loss_vfl_aux_4: 0.3757 (0.3705)  loss_vfl_dn_0: 0.3544 (0.3527)  loss_vfl_dn_1: 0.3198 (0.3189)  loss_vfl_dn_2: 0.3155 (0.3147)  loss_vfl_dn_3: 0.3138 (0.3135)  loss_vfl_dn_4: 0.3136 (0.3131)  loss_vfl_dn_5: 0.3132 (0.3131)  loss_vfl_enc_0: 0.4825 (0.4710)  time: 0.6116  data: 0.0100  max mem: 5639
Epoch: [3]  [1400/1519]  eta: 0:01:04  lr: 0.000004  lr2: 0.000040  loss: 10.4325 (10.3358)  loss_bbox: 0.1372 (0.1278)  loss_bbox_aux_0: 0.1378 (0.1315)  loss_bbox_aux_1: 0.1356 (0.1288)  loss_bbox_aux_2: 0.1355 (0.1278)  loss_bbox_aux_3: 0.1368 (0.1278)  loss_bbox_aux_4: 0.1372 (0.1277)  loss_bbox_dn_0: 0.1582 (0.1512)  loss_bbox_dn_1: 0.1269 (0.1246)  loss_bbox_dn_2: 0.1226 (0.1209)  loss_bbox_dn_3: 0.1201 (0.1182)  loss_bbox_dn_4: 0.1189 (0.1171)  loss_bbox_dn_5: 0.1189 (0.1172)  loss_bbox_enc_0: 0.1551 (0.1519)  loss_giou: 0.3079 (0.3094)  loss_giou_aux_0: 0.3151 (0.3172)  loss_giou_aux_1: 0.3085 (0.3113)  loss_giou_aux_2: 0.3068 (0.3096)  loss_giou_aux_3: 0.3076 (0.3091)  loss_giou_aux_4: 0.3079 (0.3093)  loss_giou_dn_0: 0.3325 (0.3318)  loss_giou_dn_1: 0.2804 (0.2787)  loss_giou_dn_2: 0.2738 (0.2723)  loss_giou_dn_3: 0.2714 (0.2707)  loss_giou_dn_4: 0.2707 (0.2702)  loss_giou_dn_5: 0.2707 (0.2702)  loss_giou_enc_0: 0.3661 (0.3648)  loss_vfl: 0.3694 (0.3701)  loss_vfl_aux_0: 0.4469 (0.4503)  loss_vfl_aux_1: 0.4021 (0.3968)  loss_vfl_aux_2: 0.3801 (0.3800)  loss_vfl_aux_3: 0.3714 (0.3733)  loss_vfl_aux_4: 0.3704 (0.3708)  loss_vfl_dn_0: 0.3535 (0.3528)  loss_vfl_dn_1: 0.3217 (0.3189)  loss_vfl_dn_2: 0.3164 (0.3148)  loss_vfl_dn_3: 0.3154 (0.3136)  loss_vfl_dn_4: 0.3149 (0.3132)  loss_vfl_dn_5: 0.3149 (0.3132)  loss_vfl_enc_0: 0.4572 (0.4711)  time: 0.5365  data: 0.0107  max mem: 5639
Epoch: [3]  [1500/1519]  eta: 0:00:10  lr: 0.000004  lr2: 0.000040  loss: 9.9746 (10.3316)  loss_bbox: 0.1238 (0.1278)  loss_bbox_aux_0: 0.1226 (0.1315)  loss_bbox_aux_1: 0.1222 (0.1288)  loss_bbox_aux_2: 0.1250 (0.1278)  loss_bbox_aux_3: 0.1242 (0.1277)  loss_bbox_aux_4: 0.1238 (0.1277)  loss_bbox_dn_0: 0.1459 (0.1512)  loss_bbox_dn_1: 0.1186 (0.1246)  loss_bbox_dn_2: 0.1159 (0.1209)  loss_bbox_dn_3: 0.1120 (0.1182)  loss_bbox_dn_4: 0.1101 (0.1171)  loss_bbox_dn_5: 0.1101 (0.1171)  loss_bbox_enc_0: 0.1509 (0.1519)  loss_giou: 0.2875 (0.3091)  loss_giou_aux_0: 0.2928 (0.3169)  loss_giou_aux_1: 0.2914 (0.3110)  loss_giou_aux_2: 0.2898 (0.3093)  loss_giou_aux_3: 0.2856 (0.3088)  loss_giou_aux_4: 0.2852 (0.3090)  loss_giou_dn_0: 0.3261 (0.3316)  loss_giou_dn_1: 0.2711 (0.2785)  loss_giou_dn_2: 0.2598 (0.2721)  loss_giou_dn_3: 0.2598 (0.2705)  loss_giou_dn_4: 0.2578 (0.2700)  loss_giou_dn_5: 0.2579 (0.2700)  loss_giou_enc_0: 0.3457 (0.3645)  loss_vfl: 0.3601 (0.3701)  loss_vfl_aux_0: 0.4472 (0.4503)  loss_vfl_aux_1: 0.4008 (0.3968)  loss_vfl_aux_2: 0.3708 (0.3799)  loss_vfl_aux_3: 0.3713 (0.3732)  loss_vfl_aux_4: 0.3664 (0.3707)  loss_vfl_dn_0: 0.3501 (0.3527)  loss_vfl_dn_1: 0.3131 (0.3189)  loss_vfl_dn_2: 0.3082 (0.3147)  loss_vfl_dn_3: 0.3076 (0.3135)  loss_vfl_dn_4: 0.3067 (0.3131)  loss_vfl_dn_5: 0.3063 (0.3131)  loss_vfl_enc_0: 0.4705 (0.4712)  time: 0.4487  data: 0.0094  max mem: 5639
Epoch: [3]  [1518/1519]  eta: 0:00:00  lr: 0.000004  lr2: 0.000040  loss: 9.9534 (10.3297)  loss_bbox: 0.1253 (0.1278)  loss_bbox_aux_0: 0.1280 (0.1315)  loss_bbox_aux_1: 0.1247 (0.1288)  loss_bbox_aux_2: 0.1242 (0.1278)  loss_bbox_aux_3: 0.1250 (0.1277)  loss_bbox_aux_4: 0.1253 (0.1277)  loss_bbox_dn_0: 0.1367 (0.1511)  loss_bbox_dn_1: 0.1127 (0.1246)  loss_bbox_dn_2: 0.1097 (0.1208)  loss_bbox_dn_3: 0.1066 (0.1181)  loss_bbox_dn_4: 0.1053 (0.1171)  loss_bbox_dn_5: 0.1053 (0.1171)  loss_bbox_enc_0: 0.1423 (0.1519)  loss_giou: 0.2994 (0.3091)  loss_giou_aux_0: 0.3101 (0.3169)  loss_giou_aux_1: 0.2994 (0.3110)  loss_giou_aux_2: 0.2971 (0.3093)  loss_giou_aux_3: 0.2984 (0.3088)  loss_giou_aux_4: 0.2994 (0.3090)  loss_giou_dn_0: 0.3168 (0.3315)  loss_giou_dn_1: 0.2658 (0.2785)  loss_giou_dn_2: 0.2580 (0.2721)  loss_giou_dn_3: 0.2572 (0.2704)  loss_giou_dn_4: 0.2570 (0.2699)  loss_giou_dn_5: 0.2570 (0.2699)  loss_giou_enc_0: 0.3561 (0.3645)  loss_vfl: 0.3527 (0.3699)  loss_vfl_aux_0: 0.4290 (0.4501)  loss_vfl_aux_1: 0.3842 (0.3966)  loss_vfl_aux_2: 0.3602 (0.3798)  loss_vfl_aux_3: 0.3555 (0.3731)  loss_vfl_aux_4: 0.3522 (0.3706)  loss_vfl_dn_0: 0.3478 (0.3526)  loss_vfl_dn_1: 0.3136 (0.3188)  loss_vfl_dn_2: 0.3083 (0.3146)  loss_vfl_dn_3: 0.3069 (0.3135)  loss_vfl_dn_4: 0.3065 (0.3130)  loss_vfl_dn_5: 0.3066 (0.3130)  loss_vfl_enc_0: 0.4543 (0.4710)  time: 0.4434  data: 0.0089  max mem: 5639
Epoch: [3] Total time: 0:13:31 (0.5340 s / it)
Averaged stats: lr: 0.000004  lr2: 0.000040  loss: 9.9534 (10.3297)  loss_bbox: 0.1253 (0.1278)  loss_bbox_aux_0: 0.1280 (0.1315)  loss_bbox_aux_1: 0.1247 (0.1288)  loss_bbox_aux_2: 0.1242 (0.1278)  loss_bbox_aux_3: 0.1250 (0.1277)  loss_bbox_aux_4: 0.1253 (0.1277)  loss_bbox_dn_0: 0.1367 (0.1511)  loss_bbox_dn_1: 0.1127 (0.1246)  loss_bbox_dn_2: 0.1097 (0.1208)  loss_bbox_dn_3: 0.1066 (0.1181)  loss_bbox_dn_4: 0.1053 (0.1171)  loss_bbox_dn_5: 0.1053 (0.1171)  loss_bbox_enc_0: 0.1423 (0.1519)  loss_giou: 0.2994 (0.3091)  loss_giou_aux_0: 0.3101 (0.3169)  loss_giou_aux_1: 0.2994 (0.3110)  loss_giou_aux_2: 0.2971 (0.3093)  loss_giou_aux_3: 0.2984 (0.3088)  loss_giou_aux_4: 0.2994 (0.3090)  loss_giou_dn_0: 0.3168 (0.3315)  loss_giou_dn_1: 0.2658 (0.2785)  loss_giou_dn_2: 0.2580 (0.2721)  loss_giou_dn_3: 0.2572 (0.2704)  loss_giou_dn_4: 0.2570 (0.2699)  loss_giou_dn_5: 0.2570 (0.2699)  loss_giou_enc_0: 0.3561 (0.3645)  loss_vfl: 0.3527 (0.3699)  loss_vfl_aux_0: 0.4290 (0.4501)  loss_vfl_aux_1: 0.3842 (0.3966)  loss_vfl_aux_2: 0.3602 (0.3798)  loss_vfl_aux_3: 0.3555 (0.3731)  loss_vfl_aux_4: 0.3522 (0.3706)  loss_vfl_dn_0: 0.3478 (0.3526)  loss_vfl_dn_1: 0.3136 (0.3188)  loss_vfl_dn_2: 0.3083 (0.3146)  loss_vfl_dn_3: 0.3069 (0.3135)  loss_vfl_dn_4: 0.3065 (0.3130)  loss_vfl_dn_5: 0.3066 (0.3130)  loss_vfl_enc_0: 0.4543 (0.4710)
Test:  [  0/165]  eta: 0:07:17    time: 2.6538  data: 2.4232  max mem: 5639
Test:  [ 10/165]  eta: 0:01:11    time: 0.4625  data: 0.2471  max mem: 5639
Test:  [ 20/165]  eta: 0:00:55    time: 0.2689  data: 0.0311  max mem: 5639
Test:  [ 30/165]  eta: 0:00:44    time: 0.2565  data: 0.0246  max mem: 5639
Test:  [ 40/165]  eta: 0:00:39    time: 0.2492  data: 0.0236  max mem: 5639
Test:  [ 50/165]  eta: 0:00:34    time: 0.2595  data: 0.0303  max mem: 5639
Test:  [ 60/165]  eta: 0:00:30    time: 0.2299  data: 0.0223  max mem: 5639
Test:  [ 70/165]  eta: 0:00:27    time: 0.2653  data: 0.0273  max mem: 5639
Test:  [ 80/165]  eta: 0:00:24    time: 0.2658  data: 0.0253  max mem: 5639
Test:  [ 90/165]  eta: 0:00:20    time: 0.2294  data: 0.0226  max mem: 5639
Test:  [100/165]  eta: 0:00:18    time: 0.2564  data: 0.0252  max mem: 5639
Test:  [110/165]  eta: 0:00:15    time: 0.2515  data: 0.0219  max mem: 5639
Test:  [120/165]  eta: 0:00:12    time: 0.2573  data: 0.0315  max mem: 5639
Test:  [130/165]  eta: 0:00:09    time: 0.2467  data: 0.0235  max mem: 5639
Test:  [140/165]  eta: 0:00:06    time: 0.2132  data: 0.0199  max mem: 5639
Test:  [150/165]  eta: 0:00:03    time: 0.2463  data: 0.0290  max mem: 5639
Test:  [160/165]  eta: 0:00:01    time: 0.2409  data: 0.0199  max mem: 5639
Test:  [164/165]  eta: 0:00:00    time: 0.2132  data: 0.0221  max mem: 5639
Test: Total time: 0:00:43 (0.2616 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=28.31s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
best_stat: {'epoch': 0, 'coco_eval_bbox': 0.4708596759809729}
Epoch: [4]  [   0/1519]  eta: 3:37:55  lr: 0.000004  lr2: 0.000040  loss: 10.8521 (10.8521)  loss_bbox: 0.1160 (0.1160)  loss_bbox_aux_0: 0.1267 (0.1267)  loss_bbox_aux_1: 0.1211 (0.1211)  loss_bbox_aux_2: 0.1172 (0.1172)  loss_bbox_aux_3: 0.1170 (0.1170)  loss_bbox_aux_4: 0.1160 (0.1160)  loss_bbox_dn_0: 0.1510 (0.1510)  loss_bbox_dn_1: 0.1208 (0.1208)  loss_bbox_dn_2: 0.1182 (0.1182)  loss_bbox_dn_3: 0.1138 (0.1138)  loss_bbox_dn_4: 0.1108 (0.1108)  loss_bbox_dn_5: 0.1108 (0.1108)  loss_bbox_enc_0: 0.1640 (0.1640)  loss_giou: 0.3381 (0.3381)  loss_giou_aux_0: 0.3521 (0.3521)  loss_giou_aux_1: 0.3435 (0.3435)  loss_giou_aux_2: 0.3397 (0.3397)  loss_giou_aux_3: 0.3388 (0.3388)  loss_giou_aux_4: 0.3380 (0.3380)  loss_giou_dn_0: 0.3646 (0.3646)  loss_giou_dn_1: 0.3063 (0.3063)  loss_giou_dn_2: 0.2995 (0.2995)  loss_giou_dn_3: 0.2987 (0.2987)  loss_giou_dn_4: 0.2970 (0.2970)  loss_giou_dn_5: 0.2970 (0.2970)  loss_giou_enc_0: 0.4171 (0.4171)  loss_vfl: 0.3830 (0.3830)  loss_vfl_aux_0: 0.4727 (0.4727)  loss_vfl_aux_1: 0.4220 (0.4220)  loss_vfl_aux_2: 0.3982 (0.3982)  loss_vfl_aux_3: 0.3923 (0.3923)  loss_vfl_aux_4: 0.3887 (0.3887)  loss_vfl_dn_0: 0.3616 (0.3616)  loss_vfl_dn_1: 0.3244 (0.3244)  loss_vfl_dn_2: 0.3191 (0.3191)  loss_vfl_dn_3: 0.3184 (0.3184)  loss_vfl_dn_4: 0.3178 (0.3178)  loss_vfl_dn_5: 0.3174 (0.3174)  loss_vfl_enc_0: 0.5026 (0.5026)  time: 8.6078  data: 5.9955  max mem: 5639
Epoch: [4]  [ 100/1519]  eta: 0:14:31  lr: 0.000004  lr2: 0.000040  loss: 10.4312 (10.2001)  loss_bbox: 0.1245 (0.1225)  loss_bbox_aux_0: 0.1299 (0.1265)  loss_bbox_aux_1: 0.1240 (0.1239)  loss_bbox_aux_2: 0.1252 (0.1229)  loss_bbox_aux_3: 0.1241 (0.1221)  loss_bbox_aux_4: 0.1245 (0.1223)  loss_bbox_dn_0: 0.1520 (0.1434)  loss_bbox_dn_1: 0.1190 (0.1183)  loss_bbox_dn_2: 0.1137 (0.1146)  loss_bbox_dn_3: 0.1107 (0.1123)  loss_bbox_dn_4: 0.1101 (0.1114)  loss_bbox_dn_5: 0.1102 (0.1114)  loss_bbox_enc_0: 0.1540 (0.1457)  loss_giou: 0.3022 (0.3090)  loss_giou_aux_0: 0.3109 (0.3177)  loss_giou_aux_1: 0.3032 (0.3108)  loss_giou_aux_2: 0.3037 (0.3094)  loss_giou_aux_3: 0.3025 (0.3086)  loss_giou_aux_4: 0.3021 (0.3087)  loss_giou_dn_0: 0.3255 (0.3302)  loss_giou_dn_1: 0.2735 (0.2775)  loss_giou_dn_2: 0.2684 (0.2709)  loss_giou_dn_3: 0.2658 (0.2694)  loss_giou_dn_4: 0.2653 (0.2689)  loss_giou_dn_5: 0.2654 (0.2690)  loss_giou_enc_0: 0.3612 (0.3662)  loss_vfl: 0.3750 (0.3641)  loss_vfl_aux_0: 0.4631 (0.4412)  loss_vfl_aux_1: 0.3891 (0.3886)  loss_vfl_aux_2: 0.3796 (0.3740)  loss_vfl_aux_3: 0.3770 (0.3684)  loss_vfl_aux_4: 0.3743 (0.3652)  loss_vfl_dn_0: 0.3517 (0.3515)  loss_vfl_dn_1: 0.3171 (0.3183)  loss_vfl_dn_2: 0.3135 (0.3143)  loss_vfl_dn_3: 0.3114 (0.3132)  loss_vfl_dn_4: 0.3103 (0.3128)  loss_vfl_dn_5: 0.3103 (0.3128)  loss_vfl_enc_0: 0.4737 (0.4621)  time: 0.6302  data: 0.0098  max mem: 5639
Epoch: [4]  [ 200/1519]  eta: 0:12:20  lr: 0.000004  lr2: 0.000040  loss: 10.4330 (10.2286)  loss_bbox: 0.1234 (0.1249)  loss_bbox_aux_0: 0.1321 (0.1284)  loss_bbox_aux_1: 0.1235 (0.1256)  loss_bbox_aux_2: 0.1216 (0.1250)  loss_bbox_aux_3: 0.1236 (0.1241)  loss_bbox_aux_4: 0.1234 (0.1248)  loss_bbox_dn_0: 0.1502 (0.1481)  loss_bbox_dn_1: 0.1257 (0.1224)  loss_bbox_dn_2: 0.1238 (0.1187)  loss_bbox_dn_3: 0.1232 (0.1161)  loss_bbox_dn_4: 0.1220 (0.1151)  loss_bbox_dn_5: 0.1220 (0.1151)  loss_bbox_enc_0: 0.1499 (0.1487)  loss_giou: 0.2980 (0.3062)  loss_giou_aux_0: 0.3167 (0.3139)  loss_giou_aux_1: 0.3055 (0.3076)  loss_giou_aux_2: 0.3037 (0.3065)  loss_giou_aux_3: 0.2992 (0.3055)  loss_giou_aux_4: 0.2980 (0.3060)  loss_giou_dn_0: 0.3309 (0.3279)  loss_giou_dn_1: 0.2790 (0.2758)  loss_giou_dn_2: 0.2698 (0.2693)  loss_giou_dn_3: 0.2688 (0.2677)  loss_giou_dn_4: 0.2682 (0.2672)  loss_giou_dn_5: 0.2682 (0.2672)  loss_giou_enc_0: 0.3637 (0.3629)  loss_vfl: 0.3718 (0.3656)  loss_vfl_aux_0: 0.4662 (0.4490)  loss_vfl_aux_1: 0.4049 (0.3923)  loss_vfl_aux_2: 0.3850 (0.3760)  loss_vfl_aux_3: 0.3771 (0.3709)  loss_vfl_aux_4: 0.3744 (0.3665)  loss_vfl_dn_0: 0.3521 (0.3510)  loss_vfl_dn_1: 0.3198 (0.3175)  loss_vfl_dn_2: 0.3170 (0.3135)  loss_vfl_dn_3: 0.3156 (0.3123)  loss_vfl_dn_4: 0.3150 (0.3119)  loss_vfl_dn_5: 0.3150 (0.3118)  loss_vfl_enc_0: 0.4838 (0.4694)  time: 0.4921  data: 0.0103  max mem: 5639
